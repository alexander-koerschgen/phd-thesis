\documentclass[10pt, a4paper, UKenglish]{article}
%switch to koma class?
%
% notes
%%%%%%% old
% redo \\ by empty line if you want indentation (new paragraph!)
% check hyphens (- vs. --)
% packages used
%%%%%%% new
% \parindent?? make consistent choice! (tending to set parindent=0 atm)
% define the volume of a morphism, and the dagger (at what place?!)
% rethink _* notation for representation wrt torus splitting
% find good notation for categories of alebgras / dgas / mdgas over $R$
% justify notation for higher de-rham complex (higher differential forms?)
% find better symbol for higher THH (currently: TR(A))
%%%%%%% what bjorn told me
% check out generalization of teichmuller map and according relations
% find it in local something paper by hesselholt
% look at the 0 degree thing, should be in segal conjecture paper
%%%%%%% what lars told me
% find out about descent theory
% (papers witt vectors by edward miller and james somthing)
% read his the big de rham witt complex paper
% figure out if burnside witt functor is a monad / triple (-> lambda rings!)
% check out tombara functors (!?)
%%%%%%%%%%%%%%%

\title{The de Rham-Burnside-Witt complex}
\author{Valentin Krasontovitsch}

\usepackage[UKenglish]{babel}

%\usepackage{mathrsfs}
%\usepackage{color}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{units}
\usepackage[mathscr]{eucal}
\usepackage{mathtools}
\usepackage{float}
\usepackage[all]{xy}
%\SelectTips{cm}{10}
\usepackage{pb-diagram,pb-xy}
\usepackage{MnSymbol}
\usepackage{array}
\usepackage{verbatim}

\dgARROWLENGTH=1.5em

\usepackage{pstricks}
\usepackage{paralist}

%%%%%%%%%%%%%%%


%formatting
%%%%%%%%%%%
%skip geometry if using koma class!
\usepackage[a4paper, hmargin=3cm, tmargin=3.2cm, bmargin=3.2cm]{geometry}

%\newcommand\mnote[1]{\marginpar{\tiny #1}}
%\setlength{\marginparsep}{0.2cm}
%\setlength{\marginparwidth}{2.5cm}
%\setlength{\marginparpush}{0.5cm}
%\setlength{\itemsep}{0cm}
%\setlength{\parsep}{.5cm}
\setlength{\parskip}{\baselineskip}
\setlength{\parindent}{0pt}

\numberwithin{equation}{section}
\setcounter{secnumdepth}{1}
\setcounter{tocdepth}{1}

%%%%%%%%%%%


% math symbols and definitions
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\bA}{\mathbb{A}}
\newcommand{\bCF}{\mathbb{C}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\bD}{\mathbb{D}}
\newcommand{\bF}{\mathbb{F}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\rH}{\mathrm{H}}
\newcommand{\cI}{\mathcal{I}}
\newcommand{\cJ}{\mathcal{J}}
\newcommand{\bL}{\mathbb{L}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\bN}{\mathbb{N}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\bP}{\mathbb{P}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\bQ}{\mathbb{Q}}
\newcommand{\bR}{\mathbb{R}}
\newcommand{\bS}{\mathbb{S}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\bW}{\mathbb{W}}
\newcommand{\cW}{\mathcal{W}}
\newcommand{\bZ}{\mathbb{Z}}

%\renewcommand{\sin}{\mathrm{sin}}

\newcommand{\sT}{\mathbb{T}}		% \sin ( \abs{ (S^1)^k } ) simplicial torus

%%%% \bR / \bZ geometrical torus:

\def\empty{}
\newcommand*{\gT}[1][]{
	\def\temp{#1}%
	\ifx\temp\empty
		\def\mycmd{T}
	\else
		%\def\mycmd{\quotient{\bR^{#1}}{\bZ^{#1}}}
		\def\mycmd{\bR^{#1}/\bZ^{#1}}
	\fi
	\mycmd
}


\newcommand{\x}{\times}
\newcommand{\I}{[0,1]}
\newcommand{\TOP}{\mathrm{Top}}
\newcommand{\CGTOP}{\mathrm{CGTOP}}
\newcommand{\gE}{\mathbf{E}}

\newcommand{\mz}[1]{z^{(#1)}}

\newcommand{\cA}{\mathcal{A}}
\newcommand{\cL}{\mathcal{L}}

\newcommand{\blank}{{\,-\,}}
\newcommand{\norm}[1]{\left|\left|#1\right|\right|}	%norm
\newcommand{\defas}{\coloneqq}  % :=
\newcommand{\asdef}{\eqqcolon}      % =:
\newcommand{\abs}[1]{\left\vert#1\right\vert}	%absolute value
\newcommand{\with}{\mid}  % for set definitions {x \with ...}
%\newcommand{\ind}[1]{\{1,\ldots,#1\}}
\newcommand{\ind}[1]{\underline{#1}}
\newcommand{\indset}[1]{\{1,\ldots,#1\}}
\renewcommand{\k}{\ind{k}}
\newcommand{\n}{\ind{n}}
\newcommand{\onto}{\twoheadrightarrow}
\renewcommand{\subset}{\subseteq}
\newcommand{\SHC}{\mathcal{SHC}}
\newcommand{\sk}{\mathrm{sk}}
\newcommand{\ob}{\mathrm{ob}}
\newcommand{\tr}{\mathrm{tr}}
\newcommand{\sgn}{\operatorname{sgn}}
\newcommand{\pr}{\operatorname{pr}}
\newcommand{\id}{\operatorname{id}}
\newcommand{\diff}{\operatorname{d}}
\newcommand{\bez}{\mathrm{bez}}
\renewcommand{\gcd}{\mathrm{gcd}}
\newcommand{\lcm}{\mathrm{lcm}}
%\newcommand{\det}{\mathrm{det}}
\newcommand{\Hom}{\operatorname{Hom}}
\renewcommand{\hom}{\operatorname{hom}}
\newcommand{\Ho}{\operatorname{Ho}}
\newcommand{\im}{\operatorname{im}}
\newcommand{\M}{\mathrm{M}}
\newcommand{\Gl}{\operatorname{Gl}}
\newcommand{\Id}{\mathrm{Id}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\comm}[1]{\colorbox{yellow}{#1}}
\renewcommand{\H}{\mathrm{H}}
\newcommand{\Sp}{\mathrm{Sp}^O}	%whatever our model of spectra is!

\newcommand{\cndga}{\mathrm{c}n\mathrm{DGA}}
\newcommand{\calg}{\mathrm{cALG}}
\newcommand{\alg}{\mathrm{ALG}}

\newcommand{\inmatrixtwo}[4]{\left( \begin{smallmatrix} #1 & #2 \\ #3 & #4 \end{smallmatrix} \right)}
% macro for higher de rham complex, input dim n, ring R, level k
\newcommand{\omg}[3]{\Omega_{#1,#2}^{#3}}

%short macro for omega n A *
\newcommand{\omgn}{\Omega_{A,n}}

\newcommand{\dprime}{{\prime\prime}}
\newcommand{\tprime}{{\prime\prime\prime}}
%\newcommand{\deg}{\mathrm{deg}}

%\newcommand{\Hom}{\operatorname{Hom}}
%\newcommand{\Ho}{\operatorname{Ho}}
%\newcommand{\Supp}{\operatorname{supp}}


\theoremstyle{plain}
\newtheorem{thm}[equation]{Theorem}
\newtheorem{lem}[equation]{Lemma}
\newtheorem{prop}[equation]{Proposition}
\newtheorem{cor}[equation]{Corollary}

\theoremstyle{definition}
\newtheorem{defn}[equation]{Definition}
\newtheorem{quest}[equation]{Question}
\newtheorem{rem}[equation]{Remark}
\newtheorem{ex}[equation]{Example}

%\newcommand{\cupdot}{\mathbin{\mathaccent\cdot\cup}}
\newcommand{\oldto}{\to}
\renewcommand{\to}{\longrightarrow}
\newcommand{\oldmapsto}{\mapsto}
\renewcommand{\mapsto}{\longmapsto}
\newcommand{\del}{\operatorname{\partial}}
\newcommand{\sS}{\mathrm{sSet}}
\newcommand{\Set}{\mathrm{Set}}
\DeclareMathOperator*{\colim}{colim}
\DeclareMathOperator*{\hocolim}{hocolim}
\renewcommand{\d}{\operatorname{d}}

%\DeclareMathOperator*{\loday}{\Lambda}
%\newcommand{\loday}{\mathop{\vphantom{\sum}\mathchoice
%  {\vcenter{\hbox{\huge \Lambda}}}
%  {\vcenter{\hbox{\Large \Lambda}}}{\Lambda}{\Lambda}}\displaylimits}

\newcommand{\operator}[1]{\mathop{\vphantom{\sum}\mathchoice
{\vcenter{\hbox{\Large $#1$}}}
{\vcenter{\hbox{\large $#1$}}}{#1}{#1}}\displaylimits}

\newcommand{\loday}{\operator{\Lambda}}

%\DeclareMathOperator*{\loday}{\vs\Large \Lambda}
\newcommand{\const}{\mathrm{const}}

%%%% adding space on the inside of curly brackets used for sets
%
%\DeclareRobustCommand{\{}{\ifmmode\lbrace\,\else\textbraceleft\fi}
%\DeclareRobustCommand{\}}{\ifmmode\rbracespace\else\textbraceright\fi}
%\newcommand*{\rbracespace}{\,\rbrace}
%
%\makeatletter
%\let\saved@right\right
%\renewcommand*{\right}{%
%  \@ifnextchar\}{\,\saved@right\rbrace\@gobble}{\saved@right}%
%}
%\makeatletter
%
%%%%

\newcommand{\twopartdef}[4]
{
	\left\{
		\begin{array}{ll}
			#1 & #2 \\
			#3 & #4
		\end{array}
	\right.
}

\newcommand\quotient[2]{
	\mathchoice
		{% \displaystyle
			\text{\raise1ex\hbox{$#1$}\Big/\lower1ex\hbox{$#2$}}%
		}
		{% \textstyle
			#1\,/\,#2
		}
		{% \scriptstyle
			#1\,/\,#2
		}
		{% \scriptscriptstyle
			#1\,/\,#2
		}
}


\newcommand{\bigmod}[2]{{\left.\raisebox{.2em}{$#1$}\middle/\raisebox{-.2em}{$#2$}\right.}}

\newcommand*{\Cdot}{%}[1][1.25]{%
  {\mathpalette{\CdotAux{1.25}}\cdot}%
}
%
\newcommand{\myrightrightarrows}{\substack{\longrightarrow\\[-1em] \longrightarrow}
}
%
%\newcommand*{\myrightarrow}[2]{\xrightarrow{\mathmakebox[\trollo]{#1}}}
%
\newcommand*{\crightarrow}[2]{%
	\xrightarrow{\mathmakebox[#1\trollo]{#2}}
}
%
\newcommand*{\myrightarrow}[2][]{%
  \def\temp{#1}%
  \ifx\temp\empty
   \def\mycmd{\xrightarrow}%
  \else
   \def\mycmd{\xrightarrow[{\mathmakebox[\trollo]{#1}}]}%
  \fi
  \mycmd{\mathmakebox[\trollo]{#2}}%
 }
%
\newdimen\CdotAxis
\newcommand*{\CdotAux}[3]{%
  {%
    \settoheight\CdotAxis{$#2\vcenter{}$}%
    \sbox0{%
      \raisebox\CdotAxis{%
        \scalebox{#1}{%
          \raisebox{-\CdotAxis}{%
            $\mathsurround=0pt #2#3$%
          }%
        }%
      }%
    }%
    % Remove depth that arises from scaling.
    \dp0=0pt %
    % Decrease scaled height.
    \sbox2{$#2\bullet$}%
    \ifdim\ht2<\ht0 %
      \ht0=\ht2 %
    \fi
    % Use the same width as the original \cdot.
    \sbox2{$\mathsurround=0pt #2#3$}%
    \hbox to \wd2{\hss\usebox{0}\hss}%
  }%
}

%\renewcommand*{\Cdot}{\raisebox{-0.25ex}{\scalebox{1.2}{$\cdot$}}}

\newlength{\trollo}
\settowidth{\trollo}{\scriptsize$200000$}


\newcommand{\pokescale}{0.09}

\newcommand{\adj}[1][]{\def\ArgI{#1}\adjRelayI}
\newcommand{\adjRelayI}[1][]{\def\ArgII{#1}\adjRelayII}
\newcommand{\adjRelayII}[3][2.2em]{\ensuremath{\SelectTips{cm}{10}\xymatrix@C=#1@1{{#2}\, \ar@<.5ex>[r]^-{\ArgI}^-{}="1" & \;\,{#3} \ar@<.5ex>[l]^-{\ArgII}^-{}="2"}}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
\begin{document}
\begin{abstract}
Investigating the homotopy groups of the fixed point spectra of iterated topological Hochschild homology of a commutative ring spectrum, we study the resulting Burnside-Witt complexes and prove the existence of an initial such complex, the de Rham Burnside-Witt complex. We proceed to analyse this algebraic object and compare it to the afore mentioned homotopy groups for the ring $\rH\bF_p$.
\end{abstract}
%
{\let\newpage\relax\maketitle}
\maketitle
%\setcounter{tocdepth}{1}
%
%
%%%%%%%%%%%%%%%%%%% SECTION 0 %%%%%%%%%%%%%%%%%%%
%
%
\section{Introduction}
Why is this interesting? What is some historic background? What are applications? What are you actually doing? Give an outline? What are your results? What more could be done?\\
Should include: Choice of model of ring spectra and result about equivalence (Shipley - Symmetric spectra and THH) [how much structure do we know to be preserved? comm. ring spectrum (gamma spaces not comm. on the nose, only $E_\infty$), naive equivariant spectrum, structure maps (implied by equivariant structure!?)]; TC, algebraic K-theory and cyclotomic trace (being an equivalence); algebraic version of everything; iteration stuff: red-shift conjecture (rognes), computations (rognes, ausoni);
\subsection{Acknowledgements}
Thank people %(supervisors, wife, ksju, talbot team? ...?).
\subsection{Notation}
We write $\underline{k} \coloneqq \{1 \ldots k \}$. We let $\sS$ and $\sS_*$ denote the category of simplicial sets and pointed simplicial sets, respectively. We refer to the category of (connective) ring spectra, here modelled on $\Gamma$-spaces, as $\bS-\alg$, and to commutative ring spectra by $\bS-\calg$. Given a (pro-finite) group $G$, we write $H \leq G$ whenever $H$ is an (open) subgroup of $G$. Given a morphism between two objects indexed by groups, $X(G) \to X(H)$, we index the morphism $f_G^H: X(G) \to X(H)$, reading the indices bottom to top. When no confusion is possible, we write $T^\alpha \defas [\Lambda_{\sT^n} A]^{L_\alpha}$ for an isogeny of the $n$-torus $\alpha$ and a commutative ring spectrum $A$.
\section{iterated topological Hochschild homology}
We proceed to introduce topological Hochschild homology based on a space $X$ and the structure it carries for $X = T^n$ the $n$-dimensional torus, following \cite{brun2010covering} as well as \cite{carlsson2011higher}. For details on bicategories, confer \cite{benabou1967introduction} \comm{TODO add source! include the preprint on arxiv?}.
\subsection{The Loday functor}
A bicategory $\mathcal{C}$ is in part made up of a class of 0-cells, and for any two zero-cells $A,B$ a category $\mathcal{C}(A,B)$, whose objects form the 1-cells from $A$ to $B$ and whose morphisms form the 2-cells between two given 1-cells. The bicategory of spans $W$ has 0-cells all finite cells. Given finite sets $X,Y$ the 1-cells are given as spans $ X \leftarrow A \rightarrow Y$ for some finite set $A$, and a 2-cells between two spans from $X$ to $Y$  is given as the vertical map in the following commutative diagram:
\[
\xymatrix@R-=.5em{
  %
  &
  %
  A \ar[dl] \ar[dd] \ar[dr]
  %
  \\
  X
  &
  %
  &
  Y
  \\
  %
  &
  A^\prime \ar[ul] \ar[ur]
  &
  %
}
\]
Horizontal composition is given by a functorial and conrete choice of pullback applied to the 1-cells and taking the map induced by the 2-cells between pullbacks, \comm{[make clearer or scratch - this should explain horizontal composition of 2-cells!]}, while vertical composition is composition of maps.\\
The bicategory $\operatorname{Cat}$ of small categories has small categories as 0-cells, functors as 1-cells and natural transformations as 2-cells.
\comm{add all the technical things you need from covering homology:}\\
spans, functor $\cJ$, nat traf $G^A_S$ (gamma spaces, hom space (fibrant replacement), $(\Lambda_X A)^G$ functor of conn. comm $S$-algebras that preserves conn. and has values in very special gamma spaces (Cor. 5.1.5 in Covering homology), how diagonal is constructed (Street rectification necessary! H-set, and so on...); adapt to orthogonal spectra!?
\begin{defn}\label{def_loday_functor}
We define the Loday functor for a finite set $S$ and a commutative $\bS$-algebra $A$ as hocolim category functor ...
\end{defn}

\subsection{Restriction}
Read up in bcd - higher top cyclic hom and  hm - k-theory fin alg over witt...
part of reason for using isogenies: need subgroups $H$ of $G$ such that $G/H$ can be identified naturally with $G$, kernels of surj. homos with finite kernel are an example for that.
\subsection{Frobenius}
\begin{defn}\label{def_frobenius_and_functoriality}
Let $G$ be a group, $A$ a connective commutative ring spectrum, and let $\alpha : G \to G$ be a surjective group homomorphism with finite kernel $L_\alpha$. For every other such morphism $\beta: G \to G$ we define the Frobenius map
\[ F^\alpha \defas F^\alpha_{(\beta)}: \Lambda_G(A)^{ L_{\beta\alpha} } \to \Lambda_G(A)^{ L_\alpha } \]
to be the inclusion of fixed points. This is functorial: Given $\gamma: G \to G$ as above, we have
\[ F^\alpha\beta = F^\beta F^\alpha, \]
or in more detail
\[ F^{\gamma}_{\alpha\beta\gamma} = F^{\gamma}_{\beta\gamma} F^{\beta\gamma}_{\alpha\beta\gamma}. \]

\end{defn}

\subsection{Verschiebung}
\subsection{Teichm\"uller}
\begin{defn}\label{def_Delta_alpha}\cite[Sec. 6.2]{brun2010covering}
\comm{[insert here def of $\Delta_\alpha: A \to T^\alpha$[}
\end{defn}
\begin{prop}\label{prop_iso_degree_0_structure_map_lambda}\cite[Prop. 6.2.4]{brun2010covering}
\comm{[deduce iso $W_G A \to \Lambda_{X} \H A ^G$]}
\end{prop}
\subsection{Differentials}
%
%
\begin{lem}\label{lem_decomp_matrix}\cite[Remark 3.2]{carlsson2011higher}
There is a stable splitting \comm{add $\sigma$ unstable map}%
$$\sT_+^k \simeq \bigvee_{T \subseteq \{1 \ldots k \} } S^{\abs{T}} \cong %
  \bigvee_{j = 0}^k (S^j)^{\vee\binom{k}{j}}.$$
\comm{[geometric torus $(=\bR^n/\bZ^n)$? fix notation!} Given $\alpha \in \M_{n \times k}(\bZ_p),$ this splitting yields the induced stable map of tori
$\alpha_+: (\sT^k_p)_+ \to (\sT^n_p)_+$ as a Matrix $M$ with entries indexed by pairs of subsets
$(S,T)$, $S \subseteq \ind{n}, T \subseteq \ind{k}$ with entries%
$$ M_{S,T} = \left( \sum_{f:T \onto S} \sgn(f) \prod_{j \in T} \alpha_{f(j),j} \right) \eta^{\abs T - \abs S}.$$
We will denote this process with a subindexed asterix, i.e. $(\alpha_+)_*$.% bazinga change this!!
\end{lem}
%
%
\begin{lem}\label{lem_decomp_matrix_funct}
Assuming that $\eta$ is nullhomotopic, the above splitting is functorial with respect to matrix multiplication.
\begin{proof}
Let $a \in \M_{n \times k}(\bZ_p), b \in \M_{m \times n}(\bZ_p)$, and set $A \defas (a_+)_*$, $B \defas (b_+)_*$. Observe first that $A_{S,T}$ is zero unless $S$ and $T$ have the same cardinality: If $\abs{S} > \abs{T}$, the sum is empty; if $\abs{S} < \abs{T}$, we have a positive power of $\eta$, which by assumption is zero. Observe further that for $\abs{S} = \abs{T}$, we have $A_{S,T} = a_{S,T}$, the $(S,T)$-minor of $a$.\\
Now we compute:
$$(BA)_{S,T} = \sum_{X \subseteq \ind{n}} B_{S,X} A_{X,T} = \sum_{X \subseteq \ind{n}, \abs{X} = k} b_{S,X} a_{X,T},$$
where $k = \abs{S} = \abs{T}$ and $(BA)_{S,T} = 0$ if $\abs{S} \neq \abs{T}$. On the other hand,
$$((ba_+)_*)_{S,T} = (ba)_{S,T}$$ and these two terms are equal by the Binet-Cauchy formula from linear algebra, proving that%
$$ (b_+)_*(a_+)_* = (ba_+)_*.$$
\end{proof}
\end{lem}
%
%
\begin{lem}\label{lem_decomp_mult_2}\cite[Lemma 3.1]{carlsson2011higher}
The multiplication on the $1$-torus $\sT^1_+ \wedge \sT^1_+ \to \sT^1_+$ with respect to the stable splitting is given by the matrix
\begin{equation}\label{eq_torus_mult_2}\mu_* = %
\left( \begin{array}{cccc}
1 & 0 & 0 & 0 \\
0 & 1 & 1 & \eta \\
\end{array} \right): S^0 \wedge S^1 \wedge S^1 \wedge S^2 \to S^0 \wedge S^1 .\end{equation}
\end{lem}
%
%
%\begin{cor}\label{cor_decomp_mult_n}
%Assuming that $\eta$ is nullhomotopic, the multiplication on the $n$-torus $\mu:\sT^n_+ \wedge \sT^n_+ \to \sT^n_+$ with respect to the basis obtained from the stable splitting has the following description. Let $A,B,C \subseteq \ind{n}$. Then
%$$(\mu_*)_{(A,B),C} = \twopartdef %
%{\sgn(A \cup B)\cdot\eta^k}		{A \cup B = C}%
%{0}			{\mathrm{else}}$$%
%where $k = \# A \cap B \cap C$.
%\begin{proof}
%We identify $$\sT^n_+ \wedge \sT^n_+ \simeq \bigvee_{X \subseteq \{1 \ldots n \} } S^{\abs{X}} \wedge \bigvee_{Y \subseteq \{1 \ldots n \} } S^{\abs{Y}} \simeq \bigvee_{T \subseteq \{1 \ldots 2n \} } S^{\abs{T}}$$ via the map $\psi: \cP(n) \x \cP(n) \to \cP(2n)$ sending $(A,B) \longmapsto A \cup (n + B)$, where $(n+i) \in (n+B)$ iff $i \in B$, and index %
%$$ \bigwedge_{i=1}^n (S^0 \vee S^1) \simeq \bigvee_{T \subseteq \ind n} S^{\abs T} \simeq \sT^n_+$$ by choosing $S^1$ in the $i$-th smash-factor iff $i \in T$. Keeping these indexings in mind, one obtains the above formula for the $n$-fold tensor product of the matrix from equation (\ref{eq_torus_mult_2}).
%\end{proof}
%\end{cor}
%
%
\begin{defn}\label{def_diffs} %get the p out? bazinga
Let $A$ be a (naive) left $\sT^n$-spectrum. Note that $T^n = \Sigma^\infty T^n \in \Sp$ is semistable, hence given a stable class $x \in \pi^s_k(T^n)_+$, we may choose a representative $f: S^k \wedge S^m \to \sT^n \wedge S^m $\\
%
\comm{[can $m$ be chosen to be $k$ (relevant?)? does this definition agree with hesselholt?]}\\
%
of $x = [f]$, and define the operator
	\[	d_x: \pi_0 A \to \pi_k A	\]
as the composite
	\[	\pi_0 A \oldto%
		%\xrightarrow{\mathmakebox[1.8\trollo] {S^m \wedge S^k \wedge \blank} } %
		\pi_{k+m} ( S^k \wedge S^m \wedge A ) %
			\xrightarrow{\mathmakebox[1.8\trollo]{( (\tau \circ f) \wedge A)_*}} %
		\pi_{k+m} ( S^m \wedge T^n \wedge A )
			%
	\]
	\[
			\xrightarrow{\mathmakebox[1.4\trollo]%
				{(S^m \wedge \mu)_*}} %
		\pi_{k+m} ( S^m \wedge A ) %
			\myrightarrow{\chi_{k,m}} %
		\pi_{m+k} (S^m \wedge A ) %
			\oldto
		\pi_k A,	\]
where the first and last morphism are the natural suspension isomorphism of stable homotopy groups $ S^l \wedge \blank: \pi_k(X) \to \pi_{l+k} (S^l \wedge X)$ and its inverse, respectively, $\mu: \sT^n \wedge A \to A$ is the action map, $\tau: X \wedge Y \to Y \wedge X$ is the twisting map and $\chi_{k,m} \in \Sigma_{k+m}$ is the shuffle permutation permuting the block of the first $k$ numbers past the block of the last $m$ numbers, acting on $\pi_{k+m}$ by permuting the coordinates in the source sphere. Since we examine the effect of $f$ on stable homotopy groups, and since (regarding the suspension isomorphisms) the smash product is associative, this is independent of choice of representative. We will often blur the distinction between a representative $f$ and its class $[f]=x$.\\
We restrict ourselves to a certain class of maps: Recall the stable splitting of the torus (cf. Lemma \ref{lem_decomp_matrix}). Assuming that $\eta$ is trivial, we only allow morphisms%
\[f: S^k \to (\sT_p^n)_+ \simeq \bigvee_{T \subseteq \{1 \ldots n \} } S^{\abs{T}}\] with $(f_*)_T = 0$ for all $\abs{T} \neq k$, or equivalently $\pi_*(f)=0$ for all $* \neq k$, and denote this $\bZ_p$-submodule of $\SHC(S^k,(\sT^n_p)_+)$ as $C_k$. Their collection forms the graded $\bZ_p$-submodule $C_* \subseteq \SHC(S^*,(\sT^n_p)_+)$, where the $\bZ_p$-module structure comes from the isomorphism $\pi_0(\sT_p^n) \cong \bZ_p$. % bazinga [actually, for prime 2, need to include powers of $\eta$, they come up when multiplying elts (CHECK)]
Note that this extends \cite[Definition 3.3]{carlsson2011higher}, which considers maps $$S^k \myrightarrow{\sigma} (\sT_p^k)_+ \myrightarrow{\alpha_+} (\sT_p^n)_+$$ where $\alpha:\bZ_p^k \to \bZ_p^n$ is a matrix and $\sigma$ refers to the stable splitting of the torus. In particular for $n=1$ the two definitions coincide.
Furthermore we have $C_k = 0$ for $k \notin \{0 \ldots n\}$. % bazinga [allowing powers of $\eta$ admits morphisms from further up, are they automatically zero?]
\end{defn}
%
%
\begin{prop}\label{prop_diff_derivations}
One-dimensional differentials are derivations, i.e. satisfy the Leibniz rule...
\end{prop}
\begin{proof}
\comm{write precise statement, write proof}
\end{proof}
%
\begin{lem}\label{lem_diff_alt_alg}
Assume that $p$ is an odd prime. The collection $C \defas (C_k)_{k \in \bZ}$ of maps indexing the differentials form a free exterior algebra over $\bZ_p$ with generators $e_i: S^1 \to (\sT_p^n)_+$ for $i \in \ind{n}$, where $e_i \defas e_{\{i\}}$ and (more generally) $e_A: S^{\abs{A}} \to (\sT_p^n)_+$ becomes the identity after projecting onto the $A$-th summand for $A \subseteq \ind{n}$. The product is given by the smash product of two morphisms followed by postcomposition with the multiplication on $\sT_p^n$:
$$\SHC(S^k, (\sT_p^n)_+) \otimes \SHC(S^l, (\sT_p^n)_+) \myrightarrow{\wedge}%
\SHC(S^{k+l}, (\sT_p^n)_+ \wedge (\sT_p^n)_+) \myrightarrow{\mu_*}%
\SHC(S^{k+l}, (\sT_p^n)_+).$$
\begin{proof}
We first show that $C_ *$ is isomorphic to the free graded $Z_{(p)}$-module generated by $e_A$ (in degree $\abs{A}$) for $A \subseteq \ind{n}$: We identify%
$$\SHC(S^k, (\sT_p^n)_+) \myrightarrow{\simeq} \pi_k((\sT_p^n)_+)$$%
via evaluation at the fundamental class $\iota_k \in \pi_k(S^k)$ and further identify via the stable splitting%
$$(\sT_p^n)_+ \simeq \bigvee_{T \subseteq \ind{n}} S_p^{\abs{T}}.$$%
By definition of $C_k$, postcomposition with the map induced by the projection onto $k$-dimensional summands%
$$\bigvee_{T \subseteq \ind{n}} S_p^{\abs{T}} \to \bigvee_{T \subseteq \ind{n}, \abs{T}=k} S_p^{\abs{T}}$$%
yields an isomorphism%
$$C_k \to \pi_k  \bigvee_{T \subseteq \ind{n},\abs{T}=k} S_p^{\abs{T}} .$$
Finally we compute
$$\pi_k  \bigvee_{T \subseteq \ind{n},\abs{T}=k} S_p^{\abs{T}} \cong %
    \bigoplus_{T \subseteq \ind{n},\abs{T}=k} \pi_k S_p^k \cong
    \bigoplus_{T \subseteq \ind{n},\abs{T}=k} \bZ_p,$$%
using that localization commutes with homotopy groups for symmetric spectra whose homotopy groups are finitely generated, which is the case for $S^k$.

We proceed to prove that for $A,B \subseteq \ind{n}$ we have $e_A \cdot e_B = 0$ if $A \cap B \neq \varnothing$ and $e_A \cdot e_B = \sgn(A \cup B) e_{A\cup B}$ otherwise, where the signum is taken from the permutation bringing the tupel $(AB)$ into ascending order. We use the splitting%
$$\sT^n_+ \simeq \bigwedge_{ A \subseteq \ind{n} } S^{\abs{A}} \simeq %
\bigwedge_{ i \in \ind{n} } (S^0 \vee S^1),$$
where we recall the last identification: The brackets on the right are resolved, and we obtain $S^{\abs{A}}$ by choosing $S^1$ in the $i$-th bracket if $i \in A$, and $S^0$ otherwise. We also recall Equation \ref{eq_torus_mult_2}, which describes the multiplication in terms of said splitting for $n=1$:
\begin{equation*}\mu_* = %
\left( \begin{array}{cccc}
1 & 0 & 0 & 0 \\
0 & 1 & 1 & \eta \\
\end{array} \right): S^0 \wedge S^1 \wedge S^1 \wedge S^2 \to S^0 \wedge S^1 .\end{equation*}
Let $A, B \subseteq \ind{n}$, $A = \{i_1, \ldots, i_k\}$, $B = \{j_i, \ldots, j_l \}$ with $i_1 \less \ldots \less i_k$, $j_1 \less \ldots \less j_l$. We analyze the following diagram:
\[
\xymatrix{
  S^{\abs{A}} \wedge S^{\abs{B}} \ar[r]^-{e_A \wedge e_B} \ar[dr] & %
  (\sT_p^n)_+ \wedge (\sT_p^n)_+ \ar[r]^(.55){\mu} \ar[d]^{\simeq} & %
  (\sT_p^n)_+ \ar[d]^{\simeq} \\ %
    %
  & %
  \bigwedge\limits_{i \in \n} (S^0 \vee S^1) \wedge %
    \bigwedge\limits_{i \in \n} (S^0 \vee S^1) \ar[r] & %
  \bigwedge\limits_{i \in \n} (S^0 \vee S^1).
}
\]
Since the multiplication is defined entrywise, it becomes a smash-product of one-dimensional multiplications in the lower row, represented by the matrix above. Considering the $j$-th factor in the products in the lower row, the matrix decodes to the following: We get an identity if the target is $S^0$ and both sources are $S^0$, or if the target is $S^1$ and exactly one of the two sources is $S^1$. All other cases lead to zero (recall that $\eta$ is zero, since $p$ was chosen to be odd). So we need only look at the target sphere corresponding to $A \cup B$, and we may assume that $A \cap B = \varnothing$.

Let $x \wedge y = (x_{i_1} \ldots x_{i_k}) \wedge (y_{j_1} \ldots y_{j_l}) \in S^{\abs{A}} \wedge S^{\abs{B}}$. Then the diagonal arrow takes this element to $ \tilde{x} \wedge \tilde{y}$, where $\tilde{x}_i = x_i$ if $i \in A$, and $\tilde(x)_i = \ast$, the non-basepoint of $S^0$, otherwise; $\tilde{y}$ is defined analogously. This, in turn, is taken to the element $z = (z_1 \ldots z_n)$ with
\[ z_i = \left\{
		\begin{array}{ll}
			\ast & i \nin A \cup B \\
			x_i & i \in A \\
			y_i & i \in B
		\end{array}
	\right.\]
hence the composotion $S^{\abs{A}} \wedge S^{\abs{B}} \to S^{A \cup B}$ has degree signum of the permutation bringing $(AB)$ into ascending order, and we obtain the claimed formula $e_A \cdot e_B = \sgn{(AB)} \cdot e_{A \cup B}$ for disjoint $A,B$.
\end{proof}
\end{lem}
%
%
\begin{cor}\label{cor_diffs_ext_alg}
Let $X$ be a $\sT_p^n$-spectrum. The morphism of graded abelian groups%
  \[C_* \to \SHC(S^* \wedge X, X)\]%
sending a map in $C_k$ to the corresponding differential $X \wedge S^k \to X$ is a morphism of graded rings, where multiplication of differentials is given by composition.
\begin{proof}
The assignment sending $f \in C_k$ to $\mu \circ (f \wedge X):S^k \wedge X \to X$, where $\mu$ refers to the action map $(\sT_p^n)_+ \wedge X \to X$, is by definition bijective and additive as a composition of additive maps. The multiplicativity follows from associativity of the torus action as well as functoriality of the smash product in both variables.
\end{proof}
\end{cor}
%
%
\subsection{Relations}
%
% add all the stuff coming from equivariant theory
\comm{[add (algebraic) defnitions necessary for third relation, as well as relation itself]}\\
\comm{[add remark about taking this from \cite{carlsson2011higher}]}
\begin{defn}
Given a matrix $A \in \cM_n$, we define its volume $\abs{A}$ to be the absolute value of its determinant, and we define the adjoint $A^\dagger \in \cM_n$ as the unique matrix such that $A A^\dagger = A^\dagger A = \abs{A} \cdot E_n$, where $E_n$ is the unit matrix.
\end{defn}
%
%
\begin{rem}
Note that with the above definition, if $A \in \cM_n$ is diagonal with entries $a_1, \ldots, a_n$, then $\abs{A} = \prod_i a_i$ and hence $A^\dagger_j = \prod_{i \neq j} a_i$.
\end{rem}
%
%
\begin{lem}\cite[Lemma 3.17]{carlsson2011higher}
Let $\alpha$, $\beta \in \cM_n \defas \M_n(\bZ_p) \cap \Gl_n(\bQ_p)$, $l \in \M_{n \times k}(\bZ_p)$. Then $F^\alpha d_l V_\alpha$ is homotopic to the composite
$$\begin{xy}
\xymatrix{
  S^k \wedge T^\beta \ar[r]^-{\sigma} &%
  (\sT^k_p)_+ \wedge T^\beta \ar[r]^-{l_+} &%
  (\sT^n_p)_+ \wedge T^\beta \ar[r]^-{(\alpha_+)^\dagger} &%
  (\sT^n_p)_+ \wedge T^\beta \ar[r]^-{\phi^\beta} &%
  (\sT^n_p/L_\beta)_+ \wedge T^\beta \ar[r]^-{\mu} &%
  T^\beta
  }%
\end{xy},$$
where $(\alpha_+)^\dagger \defas \tr_\alpha\phi^\alpha_+$ and the map $\tr_\alpha: (\sT^n_p/L_\alpha)_+ \to (\sT^n_p)_+$ is the transfer.
\end{lem}
%
%
%%%%%%%% use the following remark as an explanation for why we have to extend the definition of differentials
\begin{rem}\label{rem_dagger_as_matrix}
Writing $\alpha = \tilde\gamma \delta \gamma$ with $\tilde\gamma,\gamma \in \Gl_n(\bZ_p)$ and $\delta$ a diagonal matrix with powers of $p\,$ as entries, using that for $\gamma \in \Gl_n(\bZ_p)$ we have $\phi^\gamma = \gamma^{-1}$ and $\tr_\gamma = \Id$, we obtain%
$$(\alpha_+)^\dagger = (\gamma^{-1})_+ (\delta_+)^\dagger (\tilde\gamma^{-1})_+$$
where (by \cite[Corollary 3.16]{carlsson2011higher}) the splitting $\sT^1 \simeq S^0 \vee S^1$ yields $(\delta_+)^\dagger = \bigotimes_j D^{(j)}$ with%
\begin{equation}\label{eq_diag_dagger}D^{(j)} \defas %
\left( \begin{array}{cc}
\delta_{jj} & (\delta_{jj} - 1) \eta \\
0 & 1 \\
\end{array} \right).\end{equation}
We consider the composite%
$$\begin{xy}
\xymatrix{
  S^k \ar[r]^-{\sigma} &%
  (\sT^k_p)_+ \ar[r]^-{l_+} &%
  (\sT^n_p)_+ \ar[r]^-{(\alpha_+)^\dagger} &%
  (\sT^n_p)_+%
  }%
\end{xy},$$
our goal being to substitute the last two maps by a map induced by an $(n \times k)$ -- matrix with coefficients in $\bZ_p$ without changing the composite. We first write $(\delta_+)^\dagger$ in the basis given by Lemma \ref{lem_decomp_matrix}. For this we use the bijection
$$\{0,1\}^n \to \cP(\ind{n}),\;\; (i_k) \longmapsto A \defas \{ x \in \ind{n} \with i_x = 1 \}$$%
and obtain, after setting $\Delta \defas (\delta_+)^\dagger_*$:
$$ \Delta_{S,T} = \prod_{j=1}^n D^{(j)}_{S(j),T(j)}\;,$$
where $S,T$ are pulled back to functions $\ind{n} \to \{0,1\}$ by the above bijection, hence we have $S(j) = 0$ if $k \notin \ind{n}$ and $S(j) = 1$ if $k \in \ind{n}$ (likewise for $T$).\\
We now assume $\eta$ to be nullhomotopic. If we have $S \neq T$, we pick a non-diagonal entry from one of the $D^{(j)}$s, hence the product $\Delta_{S,T}$ will be zero, so $(\delta_+)^\dagger_*$ is a diagonal matrix with entries
\begin{equation}\label{eq_dagger_of_diagnoal_plus}
	\Delta_{S,S} = \prod_{j \notin S} \delta_{jj}.
\end{equation}
Note that if we follow \cite[Def. 3.7]{carlsson2011higher} and define, for $f:A \to A$ an injective morphism of abelian groups, the morphism $f^\dagger: A \to A$ to be the unique morphism satisfying $f f^\dagger = f^\dagger f = \abs{f} \cdot \id$ (where $\abs{f}$ is the cardinality of the cokernel of $f$), we obtain that the 1-dimensional block of $\Delta = (\delta_+)^\dagger_*$ corresponds exactly to $\delta^\dagger$, or in formulas: $\Delta_{\{i\},\{j\}} = \delta_{i,j}$.\\
Consider $(l_+)$ next. Since we precompose with $\sigma$, we need only consider the last column of $(l_+)_*$, which we denote $L$, and obtain
\[L_S = \sum_{f:\ind{k} \onto S} (\sgn(f) \prod_{j=1}^k l_{f(j),j}) \eta^{k - \abs{S}}.\]
Now if $k < \abs{S}$, the sum is empty, and if $k > \abs{S}$, we get a positive power of $\eta$, which is zero. Hence we need only consider the entries of $L$ with $\abs{S} = k$ (of course the same arguments show that for any entry of $(l_+)_*$ indexed by $(S,T)$ to be non-zero, we need to have $\abs{S} = \abs{T}$). In this case, $L_S$ is the $k$-minor of $l$ obtained by deleting all rows with index not in $S$, which we denote by $l_S \defas l_{S,\ind{k}}$. We use the notation $A_{S,T}$ for the $k$-minor of a matrix $A$ given by the rows indexed by $S$ and the columns indexed by $T$ (with $k=\abs{S}=\abs{T}$).\\
How does $A \defas (a_+)_*$ for an $a \in \M_n(\bZ_p)$ act on such a vector $L$ with $L_S = 0$ if $\abs{S} \neq k$? Consider a row indexed by $X$ of $A$. Since only entries of $L$ indexed by a set of cardinality $k$ are non-zero, we need only consider entries of the $X$-th row of $A$ indexed by such sets. Yet by the above remark, these will be zero unless $\abs{X} = k$ as well. So letting $S, S^\prime \subseteq \ind{n}$ with $\abs{S} = \abs{S^\prime} = k$ we get
$$A_{S^\prime,S} = \sum_{f:S \onto S^\prime} \sgn(f) \prod_{j \in S}a_{f(j),j} = a_{S^\prime, S}.$$
Now we are ready to compute, using the functoriality of the decomposition as in Lemma \ref{lem_decomp_matrix_funct}.
Recall that $$(\alpha_+)^\dagger = (\gamma^{-1})_+ (\delta_+)^\dagger (\tilde\gamma^{-1})_+.$$ We compute step by step: Let $S \subseteq \ind{n}$ with $\abs{S} = k$. To make the formulas more readable, all sums will run over subsets of $\ind{n}$.
$$ ( (\tilde\gamma_+^{-1})_* L )_S = \sum_{\abs{S^\prime} = k } %
		\gamma^{-1}_{S,S^\prime} \, l_{S^\prime},$$
$$ ( (\delta_+)^\dagger_* (\tilde\gamma_+^{-1})_* L )_S = \Delta_{S,S} ( (\tilde\gamma_+^{-1})_* L )_S =%
		\prod_{j \notin S} \delta_{jj} \sum_{ \abs{S^\prime} = k } \gamma^{-1}_{S,S^\prime}\, l_{S^\prime},$$
$$ ( (\gamma_+^{-1})_* (\delta_+)^\dagger_* (\tilde\gamma_+^{-1})_* L )_S = %
		\sum_{\abs{\tilde S} = k} \gamma^{-1}_{S,\tilde S} \prod_{j \notin \tilde S} \delta_{jj} \sum_{ \abs{S^\prime} = k } \gamma^{-1}_{\tilde S,S^\prime}\, l_{S^\prime}.$$
We want to compare this to $( \alpha^\dagger_+ )_* L$. Observe that
$ \alpha^\dagger = \tilde \gamma^{-1} \delta^\dagger \gamma^{-1},$ %
so we compute the middle map. By definition (cf. \cite[Definition 3.7]{carlsson2011higher}), $\delta \delta^\dagger = \det(\delta) \Id_{\bZ_p^n}$, hence $\delta^\dagger$ is diagonal with $\delta^\dagger_{jj} = \prod_{k \neq j} \delta_{kk}$, and finally for $S,T \subseteq \ind{n}$ we have%
$$ (\delta^\dagger_+)_{*\, S,T} = \sum_{f:T \onto S} \sgn(f) \prod_{j \in T} \delta^\dagger_{f(j),j}.$$
Assuming none of the factors to be zero implies $S = T$ and $f = \Id_S$, hence we obtain a diagonal matrix with entries%
$$ (\delta^\dagger_+)_{*\,S,S} = \prod_{j \in S} \delta^\dagger_{jj} = \prod_{j \in S} \prod_{k \neq j} \delta_{kk} = \det(\delta)^{\abs{S}-1} \prod_{j \notin S} \delta_{jj}.$$
Overall we get for $S \subseteq \ind{n}, \abs{S} = k:$
$$ ( (\tilde\gamma_+^{-1})_* (\delta^\dagger_+)_* (\gamma_+^{-1})_* L )_S = %
\det(\delta)^{k-1} \sum_{\abs{\tilde S} = k} \gamma^{-1}_{S,\tilde S} \prod_{j \notin \tilde S} \delta_{jj} \sum_{ \abs{S^\prime} = k } \gamma^{-1}_{\tilde S,S^\prime}\, l_{S^\prime}.$$
Summarizing this leads to
\begin{equation}\label{eq_dagger_comparison}
(\alpha_+)^\dagger l_+ \sigma = (\nicefrac{1}{\abs\alpha^{k-1}}\cdot\alpha^\dagger)_+ l_+ \sigma.\end{equation}
While it is true for the entries of $\alpha^\dagger$ we are concerned about, it is not true in general that we can divide by $\nicefrac{1}{\abs\alpha^{k-1}}$. Yet letting $k$ vary and choosing specific $l \in \M_{n \times k}(\bZ_p)$, we obtain an equation of matrices: For every $1 \leq k \leq n$, and for every $S \subseteq \ind n$ with $\abs S = k$ choose $l^S \in \M_{n \times k}(\bZ_p)$ such that%
$$L^S_T = \twopartdef{1}{T=S}{0}{T \neq S},$$%
where $L^S$ is the last column of $(l^S_+)_*$. Set $L^\varnothing = e_1$. Applying (\ref{eq_diag_dagger}) to $l^S$ for all $S \subseteq \ind n$ leads to
$$	(\alpha_+)^\dagger_*( L^\varnothing \ldots L^{\ind{n}} ) = %
	( \; ( \diag( 1 \ldots \nicefrac{1}{\abs\alpha^{n-1}} ) \alpha^\dagger )_+ \; )_* %
	  ( L^\varnothing \ldots L^{\ind{n}} )$$
\end{rem}
%
%
\begin{lem}\label{lem_rel_FdV_higher_differentials}
[fix this] the third relation for a higher differentials $d_I$, $I \subset \ind{n}$ looks as follows, where for $A \subset I$ we define $B \coloneqq I \setminus A$: (ignoring indices for now)
\begin{equation*}
	F d_I V = \sum{J \subset I} d_A FV d_B
\end{equation*}
Note that in this situation, $FV = VF$ (honestly).
\begin{proof}
We mimic the proof of \cite[Thm. 3.21]{carlsson2011higher}:
\end{proof}
\end{lem}
%
%
\begin{lem}\label{lem_rel_F_Delta}
Let $A$ be a connective commutative ring spectrum. Given $a \in \pi_0 A$, $\alpha, \beta \in \cM_n$, then
	\[ F_{\alpha\beta}^{\beta} \Delta_{\alpha\beta}(a) = \Delta_{\beta} (a)^{\abs{\alpha}} \in \pi_0(\Lambda_{\sT^n} A ^\beta), \]
where $\abs{\alpha}$ denotes the cardinality of the cokernel of $\alpha$.
\end{lem}
\begin{proof}
\comm{Should basically be in Covering homology... fill out details omitted in the paper!}
Sketch: $F$ commutes with $\lambda$, $\Delta_\alpha = \lambda_\alpha \omega_\alpha$ where $\omega_\alpha: A \to W_\alpha A$ the Teichm\"uller map (multiplicative, $a \mapsto \omega_G(a)$), and $F_{\alpha\beta}^\beta \omega_{\alpha\beta}(a) = \omega_\beta(a)^{\abs{\alpha}}$ (reference to corresponding formula for F: \ref{def_witt_frob}) lol sketch whatever this is the proof.
\end{proof}
%
%
\comm{Add other relations, like Fd=dF and Vd=dV}\\
\comm{add the isomorphism Witt vectors to $pi_0$ + commutes with structure}\\
\comm{remark about $A$ being a conn. comm. ring spectrum unless stated ow?}
\begin{lem}\label{lem_rel_V_d_F_d}
Given $f \in C_k$ and $\alpha \in \M_n$, we have the two relations
	\[ d_f F^\alpha = F^\alpha d_{\alpha_+ f} \]
	\[ V_\alpha d_f = d_{\alpha_+ f} V_\alpha \]
\end{lem}
%
%
\begin{lem}\label{lem_pi_0_loday_HA_A}
Let $S$ be a connected space, and for $X$ a finite set let
	\[(c_\varnothing: X \to \ob \cI) \in \cI^X\]
be the constant map with value the empty set, which induces a map
\[
	G_X^{\H A}(S^0)(c_\varnothing) \to \hocolim_{\cI^X} G_X^{\H A}(S^0) = %
	\Lambda_X \H A (S^0)
\]
given by inclusion into the homotopy colimit and evaluated at $S^0$. Considering the latter map in every degree for all finite subspaces of $S$, we obtain an induced map
  \[	\iota: G^{\H A}_S (S^0) (c_\varnothing) \to \Lambda_S \H A (S^0), \]
which is an isomorphism on the zeroeth homotopy group.
\begin{proof}
%We assume that $S$ is a finite space.
First note that we may assume, up to homotopy equivalece, that $S$ is reduced, i.e. $S_0 = \{\ast\}$ (\comm{add reference?}). Furthermore, we take $S$ to be finite. Remembering all the simplicial directions involved, we may interpret $\iota$ as a morphism of bisimplicial sets, where one direction is given by the simplicial direction of $S$, whilst the other is chosen to be the diagonal of the other two directions, i.e. the direction of the homotopy colimit (which is constant on the left hand side) as well as the last simplicial direction, yielding (e.g. for the right hand side) %
	\[ \left( [p],[q] \longmapsto X_{p,q} \defas [\hocolim_{\cI^{S_q}} G^{\H A}_{S_q} (S^0)]_p \right) . \]
We use the first quadrant spectral sequence of a bisimplicial set to compute the homotopy groups of its diagonal in terms of the iterated homtopy groups, cf. \cite[Thm. B5]{bousfield1978homotopy}:
	\[	\mathrm{E}^2_{s,t} %
	\cong \pi_t \left\{ [q] \mapsto \pi_s(X_{\ast,q}) \right\}	\]
The bisimplicial set $X$ satisfies the $\pi_*$-Kan condition (cf. \cite[B.3.1]{bousfield1978homotopy}): For each $q \geq 0$ we have that $X_{\ast, q}$ is simple, as it is the underlying space of an $\Omega$-spectrum, hence an infinite loop space, so the first homotopy group is abelian and acts trivially on all higher homotopy groups in all path components. Furthermore, the map of simplicial sets $\pi_t^h(X)_{\mathrm{free}} \to \pi_0^h (X)$ is a Kan fibration, where $[\pi_t^h(X)]_k \defas \pi_t(X_{\ast,k})$ are the "horizontal" homotopy groups, and given a simplicial set $Y$, we let $\pi_t (Y)_\mathrm{free}$ be the set of unpointed homotopy classes of maps $S^t \to \abs{Y}$ with $\pi_t(Y)_\mathrm{free} \to \pi_0(Y)$ induced by collapsing $Y$ to its path-components: \comm{add arguement or delete!}.\\
Since the spectral sequence converges and is of first quadrant type with differentials in the direction of the main diagonals, we have
	\[	E^\infty_{0,0} = E^2_{0,0} = %
	\pi_0 \{ [q] \oldmapsto \pi_0( [ \hocolim_{\cI^{S_q}} G^{\H A}_{S_q} (S^0) ]_0 ),	\]
so in order to obtain $E^2_{0,0}$ we may calculate the coequalizer of the two maps%
\[	%\SelectTips{cm}{10}
	\xymatrix@C-=0.5cm{
	\pi_0 \left[ \hocolim_{\cI^{S_1}} G^{\H A}_{S_1} (S^0) \right]
			\ar@<-.5ex>[r] \ar@<.5ex>[r] &%
	\pi_0 \left[ \hocolim_{\cI^{S_0}} G^{\H A}_{S_0} (S^0) \right]
	}
\]
induced by the differentials $d_0, d_1: S_1 \to S_0$. Since $S_0 = \{ \ast \}$, we have $d_0 = d_1: S_1 \to S_0$ and hence the maps they induce are also identical by functoriality, so the coeqalizer is equal to the target
\[ \pi_0 \left[ \hocolim_{\cI} G^{\H A}_{\{\ast\}} (S^0) \right]. \]
The same argument and naturality of the spectral sequence imply that $\iota$ induces a map
	\[	\pi_0 G_{\{\ast\}}^{\H A}(S^0)(\varnothing) \to %
	\pi_0 \hocolim_{i \in \cI} G^{\H A}_{\{\ast\}}(S^0)(i).	\]
Using B\"okstedt's Approximation Lemma (cf. e.g. \cite[Lemma 2.2.2.2]{dundas2012local}), we show that this map is an isomorphism: Note that any map $\ind{i} \to \ind{j}$ in $\cI$ just induces (an $i$-fold deloop of) the adjoint of the structure map of the spectrum $\H A$,
	\[ G_{\{\ast\}}^{\H A}(S^0)(\ind{i}) = %
	\Omega^{i}(\H A (S^i)) \to %
	\Omega^{i}\Omega^{j-i}(\H A (S^j)) \cong %
	G_{\{\ast\}}^{\H A}(S^0)(\ind{j}),	\]
which is a weak equivalence, as $\H A$ is an $\Omega$-spectrum. So, by B\"okstedt's Lemma, $\iota$ is a weak equivalence, and in particular induces an isomorphism on $\pi_0$. The claim now follows for arbitrary connected spaces $S$ by noting that homotopy groups commute with filtered colimits. \comm{[add reference?]}\\
\end{proof}
\end{lem}
This Lemmma is used in the following generalization of \cite[Lemma 1.5.6]{hesselholt1996p-typical} to iterated THH, following the strategy of the proof found there. One may ask if the same relation holds in the context of arbitrary (connective) commutative $S$-algebras as opposed to $\H A$ for a discrete ring $A$, but we limit ourselves to the latter case. We work with a simplicial model for the topological Hochschild homology, without realizing, as it gives us more pointset level control. \comm{explain more / explain action / why is this the action?} Here we pull back the $\sT^n / L_\beta$-action via
	\[ \phi_\beta:\sT^n \myrightarrow{\cong} \sT^n / L_\beta, f \mapsto \widetilde{ (\beta^{-1}f) } + L_\beta.	\]
\begin{prop}\label{prop_fdw_relation_dim1}
Let $A$ be a commutative ring, $f = [\tilde{f}: S^1 \wedge S^m \to \sT^n \wedge S^m] \in C_1$, $\alpha,\beta \in \cM_n$, $a \in A$. Then
\begin{equation*}
  %F^\alpha d_f \Delta (a) = %
  F_{\alpha\beta}^\beta d_f \Delta_{\alpha\beta} (a) =%
  \Delta_{\beta} (a)^{\abs{\alpha} - 1} d_{(\alpha^\dagger)_+ f} \Delta_{\beta}(a)%
  \in \pi_1 (\Lambda_{T^n} \H A ^{L_\beta}).%
\end{equation*}
\end{prop}
\begin{proof}
We shall prove this claim in several reductions. First, observe that both sides of the relation we intend to prove are additive in $f$, hence it suffices to show the claim for the inclusion of the top summand $\sigma: S^1 \wedge S^m \to \sT^1_+ \wedge S^m$ (cf. Lemma \ref{lem_decomp_matrix}) followed by the inclusion of the $i$-th coordinate $(e_i)_+: \sT^1_+ \to \sT^n_+$ for some $i \in \indset{n}$. We omit the plus sign in notation, both for $e_i$ and $\alpha^\dagger$, and abbreviate $d_i \defas d_{e_i}$. Note that no confusion is possible, as we are working in a one-dimensional context, where $(\alpha_+)^\dagger$ conincides with $(\alpha^\dagger)_+$ (cf. Remark \ref{rem_dagger_as_matrix}). %and denote the $i$-th column of $\alpha^dagger$ by $\alpha^\dagger e_i \asdef \alpha^dagger_i$.
This leads to the new equation
\[ F_{\alpha\beta}^\beta d_i \Delta_{\alpha\beta} (a) =%
  \Delta_{\beta} (a)^{\abs{\alpha} - 1} d_{\alpha^\dagger e_i} \Delta_{\beta}(a)%
  \in \pi_1 (\Lambda_{T^n} \H A ^{L_\beta}).%
	\]
We may also assume that $\alpha$ is diagonal, for we may deduce the general case from knowing the result for diagonal matrices: Assume $\alpha = \gamma \delta \epsilon$ with $\gamma, \epsilon \in \cM_n$ invertible and $\delta \in \cM_n$ a diagonal matrix. Recall that the Frobenius operators are contravariantly functorial (cf. Def. \ref{def_frobenius_and_functoriality}), commute with differentials as in Lemma \ref{lem_rel_V_d_F_d} and relate to $\Delta_\alpha$ according to Lemma \ref{lem_rel_F_Delta}. To enhace readibility, remember that we write $F^\alpha = F_{\alpha\beta}^\beta$.
\begin{gather}\label{eq_Fdw_reduction_diagonal_alpha}
	\nonumber %
	F^{\alpha} d_i \Delta_{\alpha \beta} (a) = %
	F^{\gamma\delta\epsilon} d_{e_i} \Delta_{\gamma\delta\epsilon\beta} (a) = %
	F^{\epsilon} F^{\delta} F^{\gamma} d_{\gamma (\gamma^{-1} e_i)}%
		\Delta_{\gamma\delta\epsilon\beta} (a) = %
		\\%%%%%%%%%%%
	\nonumber %
	F^{\epsilon} F^{\delta} d_{\gamma^{-1} e_i} F^{\gamma} %
		\Delta_{\gamma\delta\epsilon\beta} (a) = %
	F^{\epsilon} F^{\delta} d_{\gamma^{-1} e_i} \Delta_{\delta\epsilon\beta} (a) =%
		\\%%%%%%%%%%%
	\nonumber %
	F^{\epsilon} ( \Delta_{\epsilon\beta} (a)^{\abs{\delta}-1}%
		d_{\delta^\dagger \gamma^{-1} e_i} \Delta_{\epsilon\beta}(a) ) = %
	F^{\epsilon} \Delta_{\epsilon\beta} (a)^{\abs{\delta}-1}%
		F^{\epsilon} d_{\epsilon( \epsilon^{-1} \delta^\dagger \gamma^{-1} e_i )}%
		\Delta_{\epsilon\beta}(a) = %
	\\%%%%%%%%%%
	\Delta_{\beta}(a)^{\abs{\delta}-1} d_{\epsilon^{-1} \delta^\dagger \gamma^{-1} e_i}%
		F^{\epsilon}\Delta_{\epsilon\beta}(a) = %
	\Delta_{\beta}(a)^{\abs{\alpha}-1} d_{\alpha^\dagger e_i} \Delta_{\beta}(a)%
\end{gather}
We have used that $F$ is multiplicative, and that both $\abs{-}$ and $(-)^\dagger$ are multiplicative (the latter contravariantly), and that for invertible $\gamma \in \cM_n$ we have $\abs{\gamma} = 1$ and $\gamma^\dagger = \gamma^{-1}$. Note that this is logically fine: Assuming we have the formula for diagonal $\alpha$ and $d_i$, we may deduce the formula for arbitrary $d_f$ with $f: S^1 \to \sT^n$ by the first reduction and use it here to deduce the case of arbitrary $\alpha$. From here on out, we assume $\alpha$ to be diagonal with positive entries $\alpha_{i} \defas \alpha_{ii}$ for $i \in \{1,\ldots,n\}$ (and analogously for any other diagonal matrix).\\
\begin{comment}	%incomplete variant of the above deduction with different notation
\begin{gather*}
	F^{\beta}_{\alpha\beta} d_i \Delta_{\alpha \beta} (a) = %
	F^{\beta}_{\gamma\delta\epsilon\beta} d_i \Delta_{\gamma\delta\epsilon\beta} (a) = %
	F^{\beta}_{\epsilon\beta} F^{\epsilon\beta}_{\delta\epsilon\beta}%
		F^{\delta\epsilon\beta}_{\gamma\delta\epsilon\beta} d_{\gamma (\gamma^{-1} e_i)}%
		\Delta_{\gamma\delta\epsilon\beta} (a) = %
		\\%%%%%%%%%%%
	F^{\beta}_{\epsilon\beta} F^{\epsilon\beta}_{\delta\epsilon\beta}%
		 d_{\gamma^{-1} e_i} F^{\delta\epsilon\beta}_{\gamma\delta\epsilon\beta}%
		\Delta_{\gamma\delta\epsilon\beta} (a) = %
	F^{\beta}_{\epsilon\beta} F^{\epsilon\beta}_{\delta\epsilon\beta}%
		 d_{\gamma^{-1} e_i} F^{\delta\epsilon\beta}_{\gamma\delta\epsilon\beta}%
		\Delta_{\gamma\delta\epsilon\beta} (a) =%
		\\%%%%%%%%%%%
	F^{\beta}_{\epsilon\beta} F^{\epsilon\beta}_{\delta\epsilon\beta}%
		 d_{\gamma^{-1} e_i} \Delta_{\delta\epsilon\beta} (a) =
	F^{\beta}_{\epsilon\beta} ( \Delta_{\delta\epsilon\beta} (a)^{\abs{\delta}-1}%
		d_{\delta^\dagger \gamma^{-1} e_i} \Delta_{\epsilon\beta}(a) ) = %
\end{gather*}
\end{comment}
Next, we rewrite the formula for it to mirror the outcome of the reductions that are yet to come. The claim follows if we can establish that the following holds:
\begin{equation}\label{eq_Fdw_one_dim_for_diagram}
	F_{\alpha\beta}^\beta d_i \Delta_{\alpha\beta} (a) =%
	\Delta_{\beta}(a)^{(\alpha_i-1)\alpha^\dagger_i} %
		d_i (\Delta_{\beta}(a)^{\alpha^\dagger_i}),
\end{equation}
for by applying the Leibniz rule, using linearity of the differentials, and noting that $\alpha_i \alpha^\dagger_i = \abs{\alpha}$ we obtain
\begin{gather*}
	\Delta_{\beta}(a)^{(\alpha_i-1)\alpha^\dagger_i} %
		d_i (\Delta_{\beta}(a)^{\alpha^\dagger_i}) = %
	\alpha^\dagger_i \Delta_{\beta}(a)^%
		{(\alpha_i-1)\alpha^\dagger_i+\alpha^\dagger_i-1} %
		d_{e_i} \Delta_{\beta}(a) = %
	\Delta_{\beta}(a)^{\abs{\alpha}} 	d_{\alpha^\dagger e_i} \Delta_{\beta}(a).%
\end{gather*}
We proceed to recall the abbreviation $[\Lambda_{\sT^n} \H A]^{L_\alpha} = T^\alpha$ and shall prove the relation by showing that the following diagram commutes:
\begin{equation*}%\label{eq_diag_fdw_start}
	\xymatrix@C-1em{
		\pi_0 (T)
			\ar[r]^{\Delta_{\alpha\beta}}
			\ar[d]_{\Delta_* \circ \Delta_{\beta}}
		&
		\pi_0 (T^{\alpha\beta})
			\ar[rr]^-{S^1 \wedge S^m \wedge \blank}
		&
		&
		\pi_{1+m}( S^1 \wedge S^m \wedge T^{\alpha\beta} )
			\ar[d]^-{ (\tau(e_i \wedge \id)\sigma \wedge \id)_*}
		%
		\\%%%%%%%%%%%%%%%%%%%%%
		%
		\pi_0 (T^{\beta}) \otimes %
		\pi_0 (T^{\beta})
			\ar[d]_{(-)^{(\alpha_i - 1)\alpha^\dagger_i} \otimes %
				(-)^{\alpha^\dagger_i}}
		&
		%
		&
		&
		\pi_{1+m}(S^m \wedge \sT^n_+ \wedge T^{\alpha\beta})
			\ar[d]^{ (S^m \wedge \mu)_* }
		%
		\\%%%%%%%%%%%%%%%%%%%%%
		%
		\pi_0 (T^{\beta}) \otimes %
		\pi_0 (T^{\beta})
			\ar[d]_{ \id \otimes (S^1 \wedge S^m \wedge \blank) }
		&
		%
		&
		&
		\pi_{1+m}(S^m \wedge T^{\alpha\beta})
			\ar[d]^{ (S^m \wedge F_{\alpha\beta}^\beta)_* }
		%
		\\%%%%%%%%%%%%%%%%%%%%%
		%
		\pi_0 (T^{\beta}) \otimes %
		\pi_{1+m} ( S^1 \wedge S^m \wedge T^{\beta} )
			\ar[d]_{ \id \otimes (\tau (e_i \wedge \id) \sigma \wedge \id)_* }
		&
		%
		&
		&
		\pi_{1+m}(S^m \wedge T^{\beta})
			\ar[d]^{ \chi_{1,m} }
		%
		\\%%%%%%%%%%%%%%%%%%%%%
		%
		\pi_0 (T^{\beta}) \otimes %
		\pi_{1+m} ( S^m \wedge \sT^n_+ \wedge T^{\beta} )
			\ar[d]_{\id \otimes (S^m \wedge \mu)_*}
		&
		%
		&
		&
		\pi_{m+1}(S^m \wedge T^{\beta})
			\ar[d]^{ (S^m \wedge \blank)^{-1} }
		%
		%
		\\%%%%%%%%%%%%%%%%%%%%%
		%
		\pi_0 (T^{\beta}) \otimes %
		\pi_{1+m} ( S^m \wedge T^{\beta} )
			\ar[rr]_-{\id \otimes (S^m \wedge \blank)^{-1} \circ \chi_{1,m}}
		&
		&
		\pi_0 (T^{\beta}) \otimes %
		\pi_{1} ( T^{\beta} )
			\ar[r]_-{\mu}
		&
		\pi_1(T^\beta)
	}
\end{equation*}
Here $\mu$ refers to the $\sT^n$-action on (fixed points of) $T$ as well as multiplication in the homotopy groups $\pi_* T^\beta$, while $(-)^q$ refers to the map raising an element to the $q$-th power; the map $\Delta$ is the diagonal of abelian groups $A \to A \otimes A$, and all tensor products are taken over the integers. The upper composite models the left hand side of (\ref{eq_Fdw_one_dim_for_diagram}), while the lower composite models the right hand side.\\
One may verify immediately that the lower composite is equal to
\begin{multline*}%\label{eq_diag_fdw_product}
	\pi_0 (T) %
		\crightarrow{1.2}{\Delta_* \circ \Delta_\beta} 	%
	\pi_0 ( T^\beta \wedge T^\beta ) %
		\crightarrow{1.4}{ (P_1 \wedge P_2)_*}
	\pi_0 (  T^\beta \wedge T^\beta )
		\crightarrow{1.8}{S^1 \wedge S^m \wedge \blank}%
	\pi_{1+m} ( S^1 \wedge S^m \wedge T^\beta \wedge T^\beta )
\\
		\crightarrow{2.6}{[ (\tau (e_i \wedge \id) \sigma) \wedge \id]_*} %
	\pi_{1+m} ( S^m \wedge T^\beta \wedge \sT^n_+ \wedge T^\beta ) %
		\crightarrow{3.4}{(S^m \wedge \blank)^{-1} \circ \chi_{1,m} \circ (\id \wedge \mu)_*} %
	\pi_1 (T^\beta \wedge T^\beta) %
		\crightarrow{.8}{\mu_*} %
	\pi_1 (T^\beta)
\end{multline*}
where $\Delta: X \to X \wedge X$ is the diagonal map of spectra and %
\begin{equation}\label{eq_abbreviations_power_maps}
  P_1 \defas P_{(\alpha_i - 1) \alpha^\dagger_i}\;\;%
  P_2 \defas P_{\alpha^\dagger_i}
\end{equation}
are the respective power maps on $T^\beta$. We may also commute the inverse of the suspension isomorphism and the permutation with the effect of the multiplication map, as the former is natural, and the latter is given by precomposition with a permutation, while the effect of the multiplication map is given by postcomposition:
	\[
		\xymatrix@C+5em{
		\pi_{1+m} (S^m \wedge T^\beta \wedge T^\beta)	%
			\ar[r]^-{(S^m \wedge \blank)^{-1} \circ \chi_{1,m}}	%
			\ar[d]_-{(S^m \wedge \mu)_*}	%
		&
		\pi_{1} (T^\beta \wedge T^\beta)	%
			\ar[d]^-{(\mu)_*}	%
		%
		\\%%%%%%%
		%
		\pi_{1+m} (S^m \wedge T^\beta)	%
			\ar[r]_-{(S^m \wedge \blank)^{-1} \circ \chi_{1.m}}	%
		&
		\pi_1 (T^\beta)	%
		}
	\]
Hence we may cancel the suspension isomorphism and the permutation in the end of the diagram in our quest to show commutativity. To do the same to the suspension isomorphism up front, we need to commute it past $\Delta_\gamma$ (for some $\gamma$). Since the latter is not induced by a morphism of spectra, but by a morphism of spaces in degree zero, \comm{symm spec or gamma space?} %BAZINGA
we need to evaluate at $S^0$ (cf. Def. \ref{def_Delta_alpha}): We write $X_0 \defas X(S^0)$ for a spectrum $X$ and consider the following diagram, in which the top and bottom line correspond to the three above diagrams combined and final suspension isomorphism and permutation omitted:
\[
	\xymatrix@C+3em{
	\pi_0 (T)%
		\ar[r]^-{\Delta_{\alpha\beta}}%
	&
	\pi_0 (T^{\alpha\beta})%
		\ar[rr]%^-{d_f}%
	&&
	\pi_{1+m} ({S^m \wedge T^\beta})%
	%
	\\%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%
	\pi_0 (T_0)%
		\ar[u]^{\cong}%
		\ar[r]_-{(\Delta_{\alpha\beta})_*}%
	&
	\pi_0 (T_0^{\alpha\beta})%
		\ar[u]_{\cong}
		\ar[rr]%^-{d_f}%
	&&
	\pi_{1+m} ({S^m \wedge T_0^\beta})%
		\ar[u]%
	%
	\\%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%
	\pi_0 (T_0)%
		\ar@{=}[u]%
		\ar[r]^-{(\Delta_\beta)_*}%
		\ar[d]_{\cong}%
	&
	\pi_0 (T_0^{\beta})%
		\ar[rr]%
		\ar[d]_{\cong}
	&&
	\pi_{1+m} ({S^m \wedge T_0^\beta})%
		\ar@{=}[u]%
		\ar[d]%
	%
	\\%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%
	\pi_0 (T)%
		\ar[r]_-{ \Delta_{\beta} }%
	&
	\pi_0 (T^{\beta})%
		\ar[rr]%
	&&
	\pi_{1+m} ({S^m \wedge T^\beta})%
	}
\]
The vertical non-identity arrows are the inclusions of the zeroeth term into the colimit defining the stable homotopy groups, hence the two squares commute (as $\Delta_{\alpha\beta}$ is defined thusly). The indication of an isomorphism is due to the fact that both $T$ and $T^{\gamma}$ are $\Omega$-spectra (for any $\gamma \in \cM_n$). The unlabeled inner horizontal arrows are the effects of the restrictions of the maps of spectra inducing the respective outer unlabeled arrows, hence the two long rectangles commute. So to prove commutativity of the outer square it suffices to prove commutativity of the middle rectangle. Due to the naturality of the suspension morphism and the fact that $\Delta_\gamma: T_0 \to T_0^\gamma$ is actually a map of spaces, we may now commute the suspension morphism to the front, resulting in
\begin{equation*}
\xymatrix@C+1.5em{
	\pi_0 (T_0)%
		\ar[r]^-{S^1 \wedge S^m \wedge \blank}%
		\ar[d]_-{S^1 \wedge S^m \wedge \blank}%
	&
	\pi_{1+m} (S^1 \wedge S^m \wedge T_0)%
		\ar[r]^-{ (\tau e_i \sigma) \wedge \Delta_{\alpha\beta} }%
	&
	\pi_{1+m} (S^m \wedge \sT^n_+ \wedge T_0^{\alpha\beta} )%
		\ar[d]^-{\mu}%
	%
	\\%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%
	\pi_{1+m} (S^1 \wedge S^m \wedge T_0)%
		\ar[d]_{\tau (e_i \sigma \wedge (P_1 \wedge P_2) \Delta \Delta_\beta)}%
	&
	%
	&
	\pi_{1+m} (S^m \wedge T_0^{\alpha\beta})%
		\ar[d]^{F_{\alpha\beta}^\beta}%
	%
	\\%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%
	\pi_{1+m} (S^m \wedge T_0^\beta \wedge \sT^n_+ \wedge T_0^\beta)%
		\ar[r]_-{\mu}%
	&
	\pi_{1+m} (S^m \wedge T_0^\beta \wedge T_0^\beta)%
		\ar[r]_-{\mu}%
	&
	\pi_{1+m} (S^m \wedge T_0^\beta)%
}
\end{equation*}
where we omitted noting identity morphisms and the effect of morphisms on homotopy groups. Using the inclusion into the homotopy colimit
	\[ \iota: G_S^{\H A}(S^0)(c_\varnothing) \to \Lambda_S \H A	\]
from Lemma \ref{lem_pi_0_loday_HA_A} we further reduce to
	\[	\colim_{S \subset T^n} G_S^{\H A} (S_0) (c_\varnothing) \cong \Lambda_{T^n} A,	\]
which we interpret as the Loday construction in the symmetric monoidal category of pointed sets together with smash product, $(\Set_*, \wedge, S^0)$, applied to $A$ as a commutative monoid under multiplication, pointed at $1 \in A$ \comm{[make precise what this means? refer to definition?]}. The isomorphism is induced by the evaluation at the non-base point of $S^0$
\begin{equation*}
  \hom_*(\Lambda_{s\in S} S^0, \Lambda_{s \in S} \H A(S^0) \to%
    \Lambda_{s \in S} A,
\end{equation*}
using the identification $\H A(S^0) = A \otimes \tilde{\bZ}[S^0] \cong A$.\\
Consider the following diagram, extending the preceding one, which is given by the outer rows, by the inner rows. Here we note fixed points under a group $L_\alpha$ by just a superindexed $\alpha$, abbreviate the suspension morphism as $\Sigma \defas ( S^k \wedge S^m \wedge \blank )$, still omit the $\ast$ symbol as indication of effect on homotopy groups and omit noting identity morphism, and abbreviate $\hat{T} \defas \Lambda_{T^n} A$:
\begin{equation*}
\xymatrix@C-1em{
	\pi_0 (T_0)%
		\ar[r]^-{\tau\sigma\Sigma}%
	&
	\pi_{1+m} (S^m \wedge \sT^1_+ \wedge T_0)%
		\ar[r]^-{e_i \wedge \Delta_{\alpha\beta}}%
	&
	\pi_{1+m} (S^m \wedge \sT^n_+ \wedge T_0^{\alpha\beta})
		\ar[r]^-{F_{\alpha\beta}^\beta \mu}%
	&
	\pi_{1+m} (S^m \wedge T_0^\beta)
	%
	\\%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%
	\pi_0 (\hat{T})%
		\ar[u]^-{\iota}_{\cong}%
		\ar[r]%
		\ar@{=}[d]%
	&
	\pi_{1+m} (S^m \wedge \sT^1_+ \wedge \hat{T})%
		\ar[r]%
		\ar@{=}[d]%
	&
	\pi_{1+m} (S^m \wedge \sT^n_+ \wedge (\hat{T})^{\alpha\beta})%
		\ar[r]%
	&
	\pi_{1+m} (S^m \wedge (\hat{T})^\beta)%
		\ar[u]_{\iota}
		\ar@{=}[d]
	%
	\\%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%
	\pi_0 (\hat{T})%
		\ar[r]%
		\ar[d]^-{\iota}_{\cong}%
	&
	\pi_{1+m} (S^m \wedge \sT^1_+ \wedge \hat{T})%
		\ar[r]%
	&
	\pi_{1+m} (S^m \wedge \sT^n_+ \wedge (\hat{T})^\beta \wedge (\hat{T})^\beta)%
		\ar[r]%
	&
	\pi_{1+m} (S^m \wedge (\hat{T})^\beta)%
		\ar[d]_{\iota}
	%
	\\%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%
	\pi_0 (T_0)%
		\ar[r]_-*!/d 3pt/\txt{$\labelstyle\tau\sigma\Sigma$}%
	&
	\pi_{1+m} (S^m \wedge \sT^1_+ \wedge T_0)%
		\ar[r]_-*!/d 3pt/\txt{$\labelstyle e_i \wedge (P_1 \wedge P_2) \Delta \Delta_\beta$}%
	&
	\pi_{1+m} (S^m \wedge \sT^n_+ \wedge T_0^\beta \wedge T_0^\beta)
		\ar[r]_-*!/d 3pt/\txt{$\labelstyle\mu \mu \tau$}%
	&
	\pi_{1+m} (S^m \wedge T_0^\beta)
}
\end{equation*}
As before, $\mu$ refers first to the torus action, then to the multiplication. The vertical non-identity maps are, as indicated, isomorphisms, according to Lemma \ref{lem_pi_0_loday_HA_A}. The inner horizontal maps are induced by the component of $c_\varnothing$ of the respective morphisms of homotopy colimits inducing the outer maps, i.e. the top and bottom rectangle commute. Hence to prove that the top and bottom composition are equal, it suffices to prove that the (big) inner rectangle commutes.\\
At this point we would like to modify the first square of the big inner rectangle, which immediately commutes. We substitute the composition $\tau \sigma \Sigma: \pi_0(\hat T) \to \pi_{1+m} (S^m \wedge \sT^1_+ \wedge \hat{T})$ according to the commutative diagram
\begin{equation}
\xymatrix{
	\pi_0 \Lambda_{\sT^n} A%
		\ar[r]^-{\Sigma}%
		\ar[d]_-{(\iota_{c_0})_*^{-1}}%
	&%
	\pi_{1+m} (S^{1+m} \wedge \Lambda_{\sT^n} A)%
		\ar[r]^-{\tau \sigma}%
	&%
	\pi_{1+m} (S^m \wedge \sT^1_+ \wedge \Lambda_{\sT^n} A)%
	%
	\\%%%%%
	%
	\pi_0 A%
		\ar[r]_-{\Sigma}%
	&%
	\pi_0 (S^{1+m} \wedge A)
		\ar[r]_-{\tau \sigma}%
	&%
	\pi_{1+m} (S^m \wedge \sT^1 \wedge A)%
		\ar[u]_-{(\iota_{c_0})_*}%
}
\end{equation}
where $A$ is taken to be the constant simplicial set, and $\iota_{c_0}: \pi_0 A = A \to \Lambda_{\sT^n} A$ sends an $a \in A = A_q$ to the tupel $(a, c_0)$ with $c_0: \Delta^q \to \gT[n]$ the constant singular simplex with image $0 \in \gT[n]$.

We proceed by forgetting the first three maps of this composition and only regarding the rest of the rectangle. Now we may note that it suffices to prove that the corresponding diagram of spaces commutes. Although it is missing from the notation here, one may check immediately that in the resulting situation every morphism of the diagram acts as the identity on $S^m$, hence we may reduce to the same diagram without the sphere factor, and we finally obtain
\begin{equation*}
\xymatrix{
	\sT^1_+ \wedge A%
		\ar[r]^-{\iota_{c_0}}
		\ar[d]_-{\iota_{c_0}}
	&
	*!(10,0){\sT^1_+ \wedge \Lambda_{\sT^n} A}%
		\ar[r]^-{e_i \wedge \Delta_{\alpha\beta}}%
	&
	\sT^n_+ \wedge (\Lambda_{\sT^n} A)^{\alpha\beta}
		\ar[r]^-{\mu}%
	&
	(\Lambda_{\sT^n} A)^{\alpha\beta}
		\ar[dd]^{F_{\alpha\beta}^\beta}%
	%
	\\%%%%%%%%%%%%%%%%%%%%%%%
	%
	\sT^1_+ \wedge \Lambda_{\sT^n} A%
		\ar[d]_{e_i \wedge ( P_1 \wedge P_2) \Delta \Delta_\beta }%
	&
	%
	&
	%
	&
	%
	%
	\\%%%%%%%%%%%%%%%%%%%%%%%
	%
	\sT^n_+ \wedge (\Lambda_{\sT^n} A)^\beta \wedge (\Lambda_{\sT^n} A)^\beta%
		\ar[r]_-{\mu \tau}%
	&
	*!(-13,0){(\Lambda_{\sT^n} A)^\beta \wedge (\Lambda_{\sT^n} A)^\beta}%
		\ar[rr]_-{\mu}%
	&
	%
	&
	(\Lambda_{\sT^n} A)^\beta
}
\end{equation*}
It is time to touch elements, and for this we introduce the following notation. For a finite set $S$ and a pointed commutative monoid $A$, given a finite family $(s_i)_{i \in I}$, $(a_i)_{i \in I}$ in $S$ and $A$ respectively, we write
	\[ \bigwedge_{i \in I} (a_i, s_i) \in \Lambda_S A 	\]
for the element of $\Lambda_S A$ which at the point $s \in S$ has entry $\prod a_i$, where the product ranges over all $i \in I$ with $s_i = s$. This perhaps involved notation is due to the fact that we cannot always ensure that the $s_i$ are pair-wise different.\\
Proceeding with the proof, one may deduce the case of an arbitrary $\beta \in \cM_n$ from the case $\beta = \id$. Given a finite group $G$ and a finite $H$-set $S$, the bijection
	\[ \hom_{\Set} (S,A)^{H} \to \hom_{\Set} (S/H,A)\]
(where $H$ acts trivially on $A$ and $G$ acts by $g f(s) \defas gf(g^{-1}s)$ for $f:S \to A, s \in S$ on morphisms) induces in our context ($H$ abelian, $S$ free $H$-space) an isomorphism
	\[ \lambda_H: ( \Lambda_{S} A )^H \to \Lambda_{S / H} A \]
	\[	\bigwedge_{h \in H} (a,h . s) \mapsto (a,sH) \]
natural in $A$. Applied to the Loday functor this yields an equivariant isomorphism
\begin{equation*}
  \lambda_\beta: \Lambda_{\sT^n} A ^\beta \to %
    \Lambda_{\sT^n / L_\beta} A,
\end{equation*}
where the torus acts on both sides via $\phi_\beta: \sT^n \to \sT^n / L_\beta$. In order to apply this map to fixed points we rewrite
  \[%
  \Lambda_{\sT^n} A^{\alpha\beta} = %
    \left[\phi_\beta^*(\Lambda_{\sT^n} A ^\beta)\right]^%
    { \nicefrac {L_{\alpha\beta}} {L_\beta} },%
  \]%
\begin{equation}\label{eq_iterated_fixed_points_identification}
	\bigwedge\limits_{k \in L_{\alpha\beta}} (a,f+k) = %
  \bigwedge\limits_{l + L_\beta \in (\nicefrac{L_{\alpha\beta}}{L_\beta}) } %
    [ \bigwedge\limits_{h \in L_\beta} (a,f+h+l) ],
\end{equation}
utilizing the short exact sequence
\begin{equation*}
  L_\beta \myrightarrow{\mathrm{incl}} L_{\alpha\beta} \myrightarrow{\mathrm{proj}}%
    L_{\alpha\beta}/L_\beta,
\end{equation*}
and taking iterated fixed points - with respect to the action on fixed points under $L_\beta$, induced by the morphism $\phi_\beta: \sT^n \to \sT^n/L_\beta$. We may now gather this into the composition
\begin{equation*}
  \Lambda_{\sT^n} A^{\alpha\beta} = %
    \left[ \Lambda_{\sT^n} A ^\beta \right]^{ \nicefrac {L_{\alpha\beta}} {L_\beta} } %
    \myrightarrow{\lambda_\beta} \Lambda_{\sT^n / L_\beta} A^{\nicefrac {L_{\alpha\beta}} {L_\beta}} \myrightarrow{\beta_*} %
    \Lambda_{\sT^n} A^{\alpha},
\end{equation*}
where the second map is the isomorphism induced by $\beta: \sT^n \to \sT^n$, which takes $L_{\alpha\beta}/L_\beta$ isomorphically to $L_\alpha$. This composite allows us to consider the following diagram (omitting the precomposed map $\iota_{c_0}:A \to \Lambda_{\sT^n} A$ for the moment):
\begin{equation*}
\xymatrix@C-.8em{%
	\sT^1_+ \wedge \Lambda_{\sT^n} A%
		\ar[r]^-{e_i \wedge \Delta_{\alpha\beta}}%
		\ar[d]^-{\Delta_\beta}%
		\ar[dr]^{\beta_* \lambda_\beta \Delta_\beta}
	&
	{\sT^n_+ \wedge (\Lambda_{\sT^n} A)^{\alpha\beta}}%
		\ar[r]^-{\phi_{\alpha\beta}}%
		\ar[dr]^-{\beta_* \lambda_\beta}%
	&
		{(\sT^n / L_{\alpha\beta})_+%
		%{(\nicefrac{\sT^n}{L_{\alpha\beta}})_+%
		\wedge (\Lambda_{\sT^n} A)^{\alpha\beta}}%
		\ar[r]^-{\mu}%
	&
	(\Lambda_{\sT^n} A)^{\alpha\beta}%
		\ar[r]^{F_{\alpha\beta}^\beta}%
		\ar[d]_{\beta_* \lambda_\beta}%
	&
	(\Lambda_{\sT^n} A)^\beta%
		\ar[d]_{\beta_* \lambda_\beta}%
	%
	\\%%%%%%%%%%%%%%%%%%%%%%%
	%
	%
	*!(0,8){\sT^1_+ \wedge (\Lambda_{\sT^n} A)^\beta} %
		\ar[dd]^{e_i \wedge (P_1 \wedge P_2) \Delta }%
	&
	\sT^1_+ \wedge \Lambda_{\sT^n} A%
		\ar[l]!(0,-10);[]^-{\beta_* \lambda_\beta}%
		\ar[r]^-{e_i \wedge \Delta_{\alpha}}%
		\ar[d]^{e_i \wedge (P_1 \wedge P_2) \Delta }%
	&
	\sT^n_+ \wedge (\Lambda_{\sT^n} A)^{\alpha}%
		\ar[r]^-{\mu \phi_\alpha}%
	&
	(\Lambda_{\sT^n} A)^{\alpha}%
		\ar[r]^{F_{\alpha \id}^{\id}}%
	&
	(\Lambda_{\sT^n} A)%
		\ar@{=}[d]%
	%
	\\%%%%%%%%%%%%%%%%%%%%%%%
	%
	%
	&
	\sT^n_+ \wedge (\Lambda_{\sT^n} A)^{\wedge 2} % \wedge (\Lambda_{\sT^n} A)%
		\ar[rr]_-{ \mu \tau }%
	&
	%
	&
	*!(10,0){(\Lambda_{\sT^n} A)^{\wedge 2}}% \wedge (\Lambda_{\sT^n} A)}%
		\ar[r]_-{\mu}%
	&
	\Lambda_{\sT^n} A
	%
	\\%%%%%%%%%%%%%%%%%%%%%%%
	%
	\sT^n_+ \wedge ( (\Lambda_{\sT^n} A)^\beta )^{\wedge 2} % \wedge (\Lambda_{\sT^n} A)^\beta%
		\ar[rr]_-{ \mu \phi_\beta \tau}%
		\ar[ur]_-{\beta_*\lambda_\beta}%
	&
	%
	&
	( (\Lambda_{\sT^n} A)^\beta )^{\wedge 2}%
		\ar[rr]_-{\mu}
		\ar[ur]!(-10,0)_-{\beta_* \lambda_\beta}%
	&
	%
	&
	(\Lambda_{\sT^n} A)^\beta%
		\ar[u]^-{\beta_* \lambda_\beta}%
}
\end{equation*}
This diagram is in fact commutative, and we only need to inspect the upper left square, as the other parts commute due to naturality and equivariance of $\beta_* \lambda_\beta$. But the commutativity of that square may immediately be verified using the definitions of the morphisms involved and identification \ref{eq_iterated_fixed_points_identification}. Thus, after remembering and precomposing the morphism $\iota_{c_0}:A \to \Lambda_{\sT^n} A$, we have reduced the problem to the commutativity of this diagram:
\begin{equation*}
\xymatrix@C-.3em{
	\sT^1_+ \wedge A%
		\ar[r]^-{\iota_{c_0}}%
		\ar[d]_-{\iota_{c_0}}%
	&
	\sT^1_+ \wedge \Lambda_{\sT^n} A%
		\ar[r]^-{e_i \wedge \Delta_{\alpha}}%
	&
	\sT^n_+ \wedge (\Lambda_{\sT^n} A)^{\alpha}%
		\ar[r]^-{\mu}%
	&
	(\Lambda_{\sT^n} A)^{\alpha}%
		\ar[d]^{F_{\alpha\id}^{\id}}%
	%
	\\%%%%%%%%%%%%%%%%%%%%%%%
	%
	\sT^1_+ \wedge \Lambda_{\sT^n} A%
		\ar[r]_-*!/d 3pt/\txt{$\labelstyle e_i \wedge (P_1 \wedge P_2) \Delta $}
		%\ar[r]_-{e_i \wedge (P_1 \wedge P_2) \Delta }%
	&
	\sT^n_+ \wedge (\Lambda_{\sT^n} A) \wedge (\Lambda_{\sT^n} A)%
		\ar[r]_-*!/d 3pt/\txt{$\labelstyle \mu \tau $}
	&
	(\Lambda_{\sT^n} A) \wedge (\Lambda_{\sT^n} A)%
		\ar[r]_-*!/d 3pt/\txt{$\labelstyle \mu $}
	&
	(\Lambda_{\sT^n} A)%
}
\end{equation*}
When one traces an element through the diagram at this stage, one will note that the upper composition yields a range of different singular simplices, while the lower composite does not. Speaking informally, there is too much space in the huge model that we are using, as compared to the model based on the simplicial circle $S^1_\cdot$ used in \cite{hesselholt1996p-typical}. Hence we introduce a map $\psi_\alpha: \gT[n] \to \gT[n]$ that will collect things, defined thusly \comm{[analogue for p-adic tours?]}. Recall that we reduced the proof to the case of a diagonal matrix $\alpha = \mathrm{diag}(\alpha_1, \ldots, \alpha_n)$ with $\alpha_i > 0$, and define
	\[	\psi_\alpha: \gT[n] \to \gT[n], \]
	\[ x \mapsto \psi_\alpha(x)_i = %
		{\left\{
			\begin{array}{ll}
				\alpha_i x_i & 0 \leq x_i \leq \nicefrac{1}{\alpha_i} \\
				1 & \nicefrac{1}{\alpha_i} \leq x_i \leq 1
			\end{array}
		\right.}%
	\]
This map is continuous as it is continuous in each component, and it is homotopic to the identity: A homotopy is given by
	\[	H_\alpha: \gT[n] \times [0,1] \to \gT[n] \]
	\[ (x,t) \mapsto H_\alpha(x,t)_i = %
		{\left\{
			\begin{array}{ll}
				\alpha_i^t x_i & 0 \leq x_i \leq \nicefrac{1}{\alpha_i^t} \\
				1 & \nicefrac{1}{\alpha_i^t} \leq x_i \leq 1
			\end{array}
		\right.}%
	\]
This is continuous, as the entries of the matrix were chosen to be positive. We insert the morphism $\psi_\alpha$ at the end of the upper composition of the diagram whose commutativity we are trying to prove (see below). As the map is homotopic to the identity, its effect will be the identity once we apply homotopy groups.\comm{[loday functor simplicial! add remark? add proof? source ($\Gamma$-spaces)?]}\\
As we need to prove commutativity of the respective diagram of homotopy groups, we may precompose with a weak equivalence (smashed with $A$), namely
	\[ S^1_\cdot \myrightarrow{\eta} \sin \abs{S^1_\cdot} \myrightarrow{\cong}%
		\sin \bR/\bZ = \sT^1, 	\]
where $\eta$ is the unit of the adjunction between simplicial sets and topological spaces given by geometric realization and the singular set, and the unnamed map is induced by a homeomorphism $\abs{S^1_\cdot} \to \bR/\bZ$, which we make precise as follows. The non-degenerate simplices of $S^1_\cdot = \Delta[1] / \del \Delta[1]$, the standard simplicial $1$-simplex with collapsed boundary, are exactly one simplex each in degree 1 (denoted $x$) and 0 ($d_0(x)$), hence we can give the map
	\[	\abs{S^1_\cdot} = \quotient{\coprod\limits_{n} \Delta^n \times S^1_n}{\sim} \to \bR/\bZ		\]
	as (identifying a representative $t \in \bR$ with its residue class in $\bR/\bZ$)
	\[	\Delta^1 \times \{x\} \to \bR/\bZ,\;z = (z_0,z_1) \mapsto z, \]
with the standard topological $1$-simplex given as $\Delta^1 = \{(z_0,z_1) \in \bR^2 \with z_0+z_1=1, 0 \leq z_0,z_1 \leq 1\}$. Applying this to the non-degenerate simplex $x \in S^1_1$, its image in $\sT^1$ is given by
\[
	f:\Delta^1 \to \bR/\bZ, z = (z_0,z_1) \mapsto z_0.
\]
Since it suffices to check comutativity on non-degenerate simplices, and as the simplex in degree 0 is a face of the one in degree 1, we may restrict ourselves to $x$.\\
%
%
% so we proceed to describe these for $(S^1_\cdot)^k$. Considering simplices $x \in \Delta[1]_k = \hom_\Delta([k],[1])$ as tupels $x = (0, \ldots, 0,1,\dots,1) \in [1]^{[k]} = %
% \{0,1\}^{\{0 \ldots k\}}$, we write $e^k_i \in \Delta[1]_k$ for the tupel with first 1 on the $i$-th position. Then a small calculation (cf. \cite[Lemma 2.2]{krasontovitsch2012signed}) \comm{[cite own thesis? put on arxiv? add calculation?]} shows that the non-degenerate simplices in $(S^1_\cdot)^k_k$ in top degree are - up to permutation of coordinates - given by (the class of)
% 	\[ x^k = (e^k_1, \ldots, e^k_k), \]
% and all other non-degenerate simplices are faces of these, hence it suffices to restrict ourselves to $x^k$ - we will see that the result of the diagram chase depends in a straight-forward manner on the permutation of the coordinates. In order to chase this simplex through the above composition $(S^1_\cdot)^k \to \sT^k$, we note that in $\Delta[1]$ we have
% 	\[ e^k_i = s_k \ldots s_i s_0 \ldots s_0 (e^1_1)	\]
% with $(i-1)$ applications of $s_0$, while for the cosimplicial space $\Delta^*$, given a $z = (z_0, \ldots, z_k) \in \Delta^k$, we have
% 	\[s^0 \ldots s^0 s^i \ldots s^k (z) = (z_0 + \ldots + z_{i-1}, z_i + \ldots + z_k) \in \Delta^1, \]
% and we abbreviate
% \begin{equation}\label{eq_formula_degeneracy_topological_standard_simplex}
% 	 z^{(i)} \defas z_0 + \ldots + z_{i-1}
% \end{equation}
% for $z \in \bR^{k+1}, i \in \{1, \ldots, k\}$. Now we chase, for the reader's convenience,  through this composition:
% 	\[ (S^1_\cdot)^{k} \myrightarrow{\eta} \sin \abs{(S^1_\cdot)^k}  \myrightarrow{\cong}%
% 		\sin \abs{S^1_\cdot}^k  \myrightarrow{\cong} \sin (\bR/\bZ)^k  \myrightarrow{\cong}%
% 		\sin \bR^k/\bZ^k = \sT^k	\]
% The unit takes the simplex $x^k$ to the map
% 	\[\Delta^k \to \abs{(S^1_\cdot)^k},\;z \mapsto (z,x_k).\]
% The projections induce
% 	\[ \Delta^k \to \abs{S^1_\cdot}^k,\; z \mapsto ( (z,e^k_1), \ldots , (z,e^k_k) ).\]
% We now identify
% \begin{gather*}
% 	(z,e^k_i) = (z, s_k \ldots s_i s_0 \ldots s_0 (e^1_1)) = \\%
% 	(s^0 \ldots s^0 s^i \ldots s^k (z), e^1_1) = %
% 		( (z_0 + \ldots + z_{i-1}, z_i + \ldots + z_k), e^1_1) \in \abs{S^1_\cdot}
% \end{gather*}
% and are able to apply the chosen isomorphism $\abs{S^1_\cdot} \to \bR/\bZ$ to obtain that $x_k$ is sent to (cf. \ref{eq_formula_degeneracy_topological_standard_simplex})
% 	\[	f_k: \Delta^k \to (\bR/\bZ)^k \cong \bR^k/\bZ^k,\; z \mapsto (\mz{1}, \ldots, \mz{k}) \]%
%
%
Under the identification of Lemma \ref{lem_pi_0_loday_HA_A} and the construction of $\Delta_H: \Lambda_{S} A (S^0) \to [\Lambda_{S} A (S^0)]^H$ (for a finite group $H$ and afinite $H$-set $S$) in \cite[Section 6.2]{carlsson2011higher}, given $\alpha \in \cM_n$, the corresponding
	\[ \Delta_\alpha: \Lambda_{\sT^n} A \to (\Lambda_{\sT^n} A)^\alpha \]
may be described for an $a \in A$, $f:\Delta^q \to \bR^n/\bZ^n$ by
	\[ (a,f) \mapsto \bigwedge\limits_{h \in L_\alpha} (a, f+c_h).	\]
We note further that the isomorphism $\phi_\alpha: \sT^n \to \sT^n/L_\alpha$ is given by $f \mapsto \widetilde{(\alpha^{-1} f)} + L_\alpha$, where $\widetilde{(\alpha^{-1} f)}$ is a lift of $(\alpha^{-1} f)$ against the projection $\bR^n/\bZ^n \to \quotient{(\bR^n/\bZ^n)}{L_\alpha}$, as illustrated in the following diagram:
\[
\xymatrix{
	%
	&
	%
	&
	*!/r 3pt/+0{\bR/\bZ}%
		\ar[d]^{\mathrm{quot}}% \rotatebox[origin=c]{90}{$\circlearrowleft$} L_\alpha%
		\ar@(dr,ur)[du]_{L_\alpha}% arrow L_\alpha acts
	%
	\\
	%
	\Delta^q%
		\ar[r]_-{f}%
		\ar[rru]^{\widetilde{(\alpha^{-1}f)}}
	&
	\gT[n]%
		\ar[r]_-{\alpha^{-1}}%
	&
	\quotient{(\gT[n])}{L_\alpha}
}
\]
Note that the quotient map is a covering map with deck transformation group $L_\alpha$, and we take the residue class with respect to that action. The action of $\sT^n$ on $\Lambda_{\sT^n} A$ is point-wise, i.e. for $g \in \sT^n_q$, $(a,f) \in (\Lambda_{\sT^n} A)_q$ we have $g.(a,f) = (a, f+g)$, as can easily be traced through the isomorphism $G^{\H A}_S (S^0)(\const_\varnothing) \myrightarrow{\cong} \Lambda_S A$.\\
We are now ready to chase through the diagram, which we recall:
\begin{gather*}
\xymatrix@C-.5em{
	(S^1_\cdot)_+ \wedge A%
		\ar[r]^-{\eta}%
		\ar[d]_-{\eta}%
	&
	\sT^1_+ \wedge A%
		\ar[r]^-{\iota_{c_0}}%
	&
	\sT^1_+ \wedge \Lambda_{\sT^n} A%
		\ar[r]^-{e_i \wedge \Delta_{\alpha}}%
	&
	\sT^n_+ \wedge (\Lambda_{\sT^n} A) ^{\alpha}
		\ar[r]^-{\mu}%
	&
	(\Lambda_{\sT^n} A)^{\alpha}
		\ar[d]^-{F^{\id}_{\alpha \id}}
	%
	\\%%%%%%%%%
	%
	\sT^1_+ \wedge A
		\ar[d]_-{\iota_{c_0}}%
	&
	%
	&
	%
	&
	%
	&
	\Lambda_{\sT^n} A%
		\ar[d]^-{\psi_{\alpha}}%
	%
	\\%%%%%%%%%
	%
	\sT^1_+ \wedge \Lambda_{\sT^n} A%
		%\ar[rr]_-{e_i \wedge (P_1 \wedge P_2) \Delta}%
		\ar[rr]_-*!/d 3pt/\txt{$\labelstyle e_i \wedge (P_1 \wedge P_2) \Delta $}
	&
	%
	&
	\sT^n_+ \wedge \Lambda_{\sT^n} A \wedge \Lambda_{\sT^n} A%
		%\ar[r]_-{(\id \wedge \mu) (\tau \wedge \id)}%
		\ar[r]_-*!/d 3pt/\txt{$\labelstyle (\id \wedge \mu) (\tau \wedge \id) $}
	&
	\Lambda_{\sT^n} A \wedge \Lambda_{\sT^n} A%
		%\ar[r]_-{\mu}%
		\ar[r]_-*!/d 3pt/\txt{$\labelstyle \mu $}
	&
	\Lambda_{\sT^n} A
}
\end{gather*}
where the upper $\mu$ is the composite
	\[ 	\sT^n_+ \wedge (\Lambda_{\sT^n} A) ^{\alpha} \myrightarrow{\phi_\alpha} %
		(\sT^n / L_\alpha)_+ \wedge (\Lambda_{\sT^n} A) ^{\alpha} \myrightarrow{\mu} %
		(\Lambda_{\sT^n} A) ^{\alpha}, \]
while in the lower composite the first $\mu$ refers to the torus action, the second one refers to the multiplication.\\
With the above considerations, the upper composite is given on elements as
\begin{gather*}
	%\displaystyle%
	x \wedge a \mapsto %
	f \wedge (a, c_e) \mapsto %
	e_i f \wedge \loday_{\mathclap{h \in L_\alpha} } (a,c_e + c_h) \mapsto \\%
	\widetilde{(\alpha^{-1} e_i f)} + L_\alpha \wedge %
		\loday_{\mathclap{h \in L_\alpha}} (a,c_h) \mapsto %
	\loday_{\mathclap{h \in L_\alpha}} ( a , \widetilde{(\alpha^{-1} e_i f)} + c_h ) \mapsto \\ %
	\loday_{\mathclap{h \in L_\alpha}} ( a , \psi_\alpha \circ (\widetilde{(\alpha^{-1} e_i f)} + c_h) )%
\end{gather*}
We proceed to analyze the resulting singular simplices. We first choose a lift
	\[ \widetilde{(\alpha^{-1} e_i f)}: \Delta^1 \to \bR^n/\bZ^n,\; z \mapsto \widetilde{(\alpha^{-1} e_i f)}(z) \]
with
	\[\widetilde{(\alpha^{-1} e_i f)}(z)_j = \alpha_j^{-1} \cdot (e_i f(z))_j \]
for $j \in \ind{n}$. While this term is zero for $j \neq i$, for $j = i$ we have%
	\[ (e_i f (z))_i = f(z) =  z_0 \in [0,1], \] %
in particular we have
	\[ 0 \leq \alpha_i^{-1} \cdot (e_i f (z))_i \leq \alpha_i^{-1}. \]%
Given $h \in L_\alpha$, and letting $(e_j)_{j \in \ind{n}}$ denote the standard basis vectors in $\bR^n$, for each ${j \in \ind{n}}$ there is a $k_j \in \{0, \ldots, \alpha_j -1\}$ with
	\[ h = \sum_{j=1}^n \frac{k_j}{\alpha_j} \cdot e_j. \]
Note that these $k_j$ depend on $h$, which we do note record in the notation.%
% We further define $J_h \defas \{ j \in \{1, \ldots, n \} \with k_j \neq 0 \}$, and
Recalling the definition of
	\[	\psi_\alpha: \gT[n] \to \gT[n] \]
	\[ x \mapsto \psi_\alpha(x)_j = %
		{\left\{
			\begin{array}{ll}
				\alpha_j x_j & 0 \leq x_j \leq \nicefrac{1}{\alpha_j} \\
				1 & \nicefrac{1}{\alpha_j} \leq x_j \leq 1
			\end{array}
		\right.},%
	\]
we may now conclude, for $h \in L_\alpha$ as above, $z \in \Delta^1$, and $j \in \{1,\ldots,n\}$, that
	\[	\psi_\alpha( \widetilde{(\alpha^{-1} e_i f)}(z) + h )_j = %
		{\left\{
			\begin{array}{ll}
				0 & j \neq i\\
        f(z) & j = i, k_i = 0\\
				0 & j=i, k_i \neq 0,
			\end{array}
		\right.}
	\]
and thus we obtain the formula
  \[
    \psi_\alpha( \widetilde{(\alpha^{-1} e_i f)} + c_h ) = %
    {\left\{
      \begin{array}{ll}
        e_i f & k_i = 0\\
        c_e & k_i \neq 0\\
      \end{array}
    \right.}
  \]
Counting how often each case occurs, we have exactly $\prod_{j \neq i} \alpha_j = \alpha^\dagger_i$ possibilities to choose $h \in L_\alpha$ with $k_i = 0$, and analogously $(\alpha_i - 1) \prod_{j \neq i} \alpha_j = (\alpha_i - 1) \alpha^\dagger_i$ possibilities for $h \in L_\alpha$ with $k_i \neq 0$, hence the upper composite evaluated at $(x,a)$ is equal to
  \[ (a^{(\alpha_i - 1) \alpha^\dagger_i},c_e) \wedge (a^{\alpha^\dagger_i},f) \]
and chasing the same element through the lower composite, which is now a straight forward affair, proves commutativity. To recall $P_1$ and $P_2$, the reader may kindly refer to Eq. \ref{eq_abbreviations_power_maps}.\\
% \comm{[continue]} Defining, for an $A \subset \{1,\ldots,n\}$, a map $q_A: \bR^n/\bZ^n \to \bR^n/\bZ^n$ to set each coordinate $i \in A$ to zero and act as identity on the other coordinates, in symbols for $x \in \bR^n/\bZ^n$:
% 	\[q_A(x)_i = %
% 		{\left\{
% 			\begin{array}{ll}
% 				0 & i \in A \\
% 				x_i & i \notin A
% 			\end{array}
% 		\right.},
% 	\]
% we may summarize
% 	\[ \psi_\alpha( \widetilde{(\alpha^{-1} e_I f_k)} + c_h) = q_{I \cap J_h} e_I f_k. \]
% Wishing to bring this into a more interpretable form, or in a form which reminds us of (lower-dimensional) differentials, we make the following observation which follows immediately by induction: Letting $A =\{j_1 ,\ldots , j_m\} \subset \{1,\ldots,k\}$ with $j_1 < \ldots < j_m$, we have the following commutative square:
% \begin{equation*}
% 	\xymatrix{
% 	\Delta^k%
% 		\ar[r]^-{f_k}%
% 		\ar[d]_-{ s^{j_1 - 1} \ldots s^{j_m - 1} }%
% 	&
% 	\bR^k / \bZ^k%
% 		\ar[d]^-{q_A}%
% 	%
% 	\\%%%%%%%%
% 	%
% 	\Delta^{k-m}%
% 		\ar[r]_-{f_{k-m}}%
% 	&
% 	\bR^{k-m}/\bZ^{k-m}
% }
% \end{equation*}
% where the $s^j$ are the codegeneracy maps (hence superindexed) of the cosimplicial topological space of geometrix simplices $\Delta^\cdot$ and are given (for all $0 \leq j \leq k-1$) by
% 	\[ s^j: \Delta^k \to \Delta^{k-1}, %
% 		(z_0, \ldots, z_k) \mapsto (z_0, \ldots, z_j + z_{j+1}, \ldots, z_k).\]
% Rewriting as degeneracy maps $s_j$ in the singular complex we abbreviate $s_A \defas s_{j_m - 1} \ldots s_{j_1 - 1}$ ($s_\emptyset \defas \id$) and obtain for $J_h \cap I = \{j_1,\ldots,j_m\}$ with $j_m > \ldots > j_1$:
% 	\[ q_{I \cap J_h} e_I f_k = s_{I \cap J_h} (e_{I \setminus (I \cap J_h)} f_{k-m}) \in \sT^n_k = \sin_k \bR^n / \bZ^n, \]
% where we define $e_0: \gT[0] \to \gT[n]$ to \comm{[be the constant map to zero?]} send the single point to zero. Thus we have the singular simplex $s_A (e_{I \setminus A} f_{k-m})$ for every $A \subset I$ with $m \defas \abs{A}$. We determine the multiplicity of each such simplex. This depends on $h = \sum_{i=1}^n \nicefrac{k_i}{\alpha_i} \cdot e_i \in L_\alpha$, or more precisely on $J_h$, as $A = J_h \cap I$, i.e. on the number of $i \in I$ for which $k_i$ is non-zero. So given an $A \subset I$, to determine the number of $h \in L_\alpha$ with $J_h \cap I = A$ we note that $k_j \in \{0,\ldots,\alpha_i-1\}$ can be chosen freely for all $j \notin I$, while $k_i \neq 0$ if and only if $i \in A$ must hold.%
% This amounts to \comm{[find better name for this number?]}
% 	\[ \alpha_A \defas \prod_{j \notin I} \alpha_j \prod_{i \in A} (\alpha_i - 1) \]
% as the number in question. Hence we may conclude the diagram chase through the upper composite by
% 	\[ x_k \wedge a \mapsto %
% 		\loday_{A \subset I} (a^{\alpha_A}, s_A (e_{I \setminus A} f_{k-m}) ) = %
% 		\loday_{A \subset I} (a^{\alpha_A}, q_A e_I f_k ), \]
% proving commutativty of the diagram in question.\\[4ex]
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
% \comm{next steps:}\\
% \comm{solution for mistake in formula:} save the above by making this a proof of the relation for the case of a one-dimensional differential. then go on about the rest by just using the upper part of the diagram, and reducing "backwards". Or just change the lower composite to the more complicated formula, that actually turns out... and then reinterpret for higher-dimensional differentials (what will it reduce down from?), or should we reinterpret the one-dimensional case as well? at least give an argument? or we cut the proof by the reductions, just leaving the point-set level, and use that with new / modified reductions to recover the actual formula.\\
\comm{explain(?)} why action is at is does (naturality of identification pointed sets and $c_\varnothing$
%
%
\end{proof}
Interestingly enough, the analogous statement for higher-dimensional differentials follows formally, using other relations, and is an easy
\begin{cor}\label{cor_fdw_relation_arbitrary_dimensions}
Let $A$ be a commutative ring, $f = [\tilde{f}: S^k \wedge S^m \to \sT^n \wedge S^m] \in C_k$, $\alpha,\beta \in \cM_n$, $a \in A$. Then
\begin{equation*}
  F_{\alpha\beta}^\beta d_f \Delta_{\alpha\beta} (a) =%
  %\frac{1}{\abs{\alpha}}
  \abs{\alpha}^{-1}d_{(\alpha^\dagger)_+ f} \Delta_{\beta}(a^{\abs{\alpha}})%
  \in \pi_k (\Lambda_{T^n} \H A ^{L_\beta}).%
\end{equation*}
\begin{proof}
\comm{[in fact notation unnecessary as not usable in proof]} First we should define what we mean by the right hand side, for it is mere notation: Analyzing the left hand side of the above formula one may assume that it is legal to divide through the volume of $\alpha$, and may conlcude the following heuristic. Recall that $\alpha \alpha^\dagger = \abs{\alpha} \id$. Then
\begin{gather*}
  F^\alpha d_f \Delta_{\alpha\beta} (a) = %
    \abs{\alpha}^{-1} F^\alpha d_{\alpha \alpha^\dagger f}%
      \Delta_{\alpha\beta} (a) = %
    \abs{\alpha}^{-1} d_{\alpha^\dagger f} F^\alpha
      \Delta_{\alpha\beta} (a) = %
    \abs{\alpha}^{-1} d_{\alpha^\dagger f}
      ( \Delta_{\beta} (a)^{\abs{\alpha}} ),%
\end{gather*}
which leads exactly to the above formula we are trying to prove. We will now define what we mean by the right hand side of the formula. Indeed, decomposing $f = \sum_I \lambda_I e_I$ and letting $I = \{i_1, \ldots , i_k$ with $i_1 < \ldots < i_k$ we obtain
\begin{gather*}
  d_{(\alpha^\dagger)_+ f} \Delta_{\beta}(a^{\abs{\alpha}}) = %
  \sum_I \lambda_I d_{(\alpha^\dagger)_+ e_I} \Delta_{\beta}
    (a^{\abs{\alpha}}) = %
  \sum_I \lambda_I \alpha^\dagger_I d_I \Delta_{\beta}(a^{\abs{\alpha}}) = \\%
  \sum_I \lambda_I \alpha^\dagger_I d_{I \setminus \{i_1\}} d_{i_1}
    (\Delta_{\beta}(a)^{\abs{\alpha}}) = %
  \sum_I \lambda_I \alpha^\dagger_I d_{I \setminus \{i_1\}} (
    \abs{\alpha} \Delta_{\beta}(a)^{\abs{\alpha}-1} d_{i_1} \Delta_{\beta}(a) ) = \\%
  \abs{\alpha} \sum_I \lambda_I \alpha^\dagger_I d_{I \setminus \{i_1\}}
    (\Delta_{\beta}(a)^{\abs{\alpha}-1} d_{i_1} \Delta_{\beta}(a)),%
\end{gather*}
hence we may define
\begin{equation*}
	\abs{\alpha}^{-1} d_{(\alpha^\dagger)_+ f} \Delta_{\beta}(a^{\abs{\alpha}}) \defas %
	\sum_I \lambda_I \alpha^\dagger_I d_{I \setminus \{i_1\}}
    (\Delta_{\beta}(a)^{\abs{\alpha}-1} d_{i_1} \Delta_{\beta}(a)).
\end{equation*}
Obviously, this is not very elegant, and the reader may wonder why we choose to work with this notation. The reason is that it simplifies the following proof. Well, it's still not pretty, but simple. A possible solution (to the ugliness) is to figure out the iterated Leibniz rule for terms of the form $d_I (a^n)$; The inclined reader may try his or her hand at this, and see if it yields a more handy formula. \comm{[proof is not really simple; maybe i should do this myself]}\\
We proceed by applying some reductions before proving the statement by induction. As already hinted above, we may apply linearity of the differentials in their subindex and reduce to
\begin{equation*}
  F_{\alpha\beta}^\beta d_I \Delta_{\alpha\beta} (a) =%
  \abs{\alpha}^{-1}\alpha^\dagger_I d_I \Delta_{\beta}(a^{\abs{\alpha}})%
\end{equation*}
for some $I \subset \ind{n}$. Furthermore, we may reduce to the case of diagonal $\alpha = \diag(\alpha_1, \ldots, \alpha_n)$, and by inspecting Eq. \ref{eq_Fdw_reduction_diagonal_alpha} one may notice that the same proof holds when substituting $d_i$ with $d_I$. We are now ready to conclude by induction over the cardinality of $I$. The case $I = \{i\}$ was proven in Prop. \ref{prop_fdw_relation_dim1}. Let $\abs{I} >= 2$, and let $i \in I$ be maximal, $j\in I$ minimal, i.e. $d_I = d_i d_{I \setminus \{i,j\}} d_j$, abbreviate $I^\prime \defas I \setminus \{i\}$ and $I^{\prime\prime} \defas I \setminus \{i,j\}$, and write $\alpha = \hat \alpha \bar \alpha$ as the product of two diagonal matrices where $\hat \alpha$ agrees with $\alpha$ except in the $i$-th entry, which is equal to $1$, while $\bar \alpha$ has ones except in the $i$-th entry, which is $\alpha_i$; in symbols:
\begin{equation*}
	\hat \alpha = \diag(\alpha_1, \ldots, \alpha_{i-1}, 1, \alpha_{i+1}, \ldots, \alpha_n),\;%
		\bar \alpha = \diag(1,\ldots,1,\alpha_i,1,\ldots,1).
\end{equation*}
We decompose $F^\alpha$ with respect to this product, which will allow us to commute it past some of the differentials, as follows:\\
\comm{[leave out indices of Delta's? Write F's in short notation $F^\alpha$? add sign!]}
\begin{gather*}
	F_{\alpha\beta}^\beta d_I \Delta_{\alpha\beta}(a) = %
	F_{\bar\alpha\beta}^{\beta} F^{\bar\alpha\beta}_{\hat\alpha\bar\alpha\beta} d_i  d_{I^\prime} \Delta_{\alpha\beta}(a) = %
	F_{\bar\alpha\beta}^{\beta} d_i F^{\bar\alpha\beta}_{\hat\alpha\bar\alpha\beta}%
		d_{I^\prime} \Delta_{\alpha\beta}(a) = \\%
	F_{\bar\alpha\beta}^{\beta} d_i ( \hat\alpha^\dagger_{I^\prime} d_{I^{\prime\prime}}%
		( \Delta_{\bar\alpha\beta}(a)^{\abs{\hat\alpha}-1} %
		d_j \Delta_{\bar\alpha\beta}(a) ) = \\%
	(-1)^l \hat\alpha^\dagger_{I^\prime} d_{I^{\prime\prime}} F_{\bar\alpha\beta}^\beta %
		d_i ( \Delta_{\bar\alpha\beta}(a)^{\abs{\hat\alpha}-1} %
		d_j \Delta_{\bar\alpha\beta}(a) ),%
\end{gather*}
where $l$ is the sign of permuting $i$ past $I^{\prime\prime}$. We note that $\hat\alpha^\dagger_{I^\prime} = \alpha^\dagger_I$ and proceed to analyze only the right part of the last term:
\begin{gather*}
	F_{\bar\alpha\beta}^\beta d_i ( \Delta_{\bar\alpha\beta}(a)^{\abs{\hat\alpha}-1} %
		d_j \Delta_{\bar\alpha\beta}(a) ) = \\%
	F_{\bar\alpha\beta}^\beta \left[ %
    d_i ( \Delta_{\bar\alpha\beta}(a)^{\abs{\hat\alpha}-1} )%
    d_j \Delta_{\bar\alpha\beta}(a) + %
		\Delta_{\bar\alpha\beta}(a)^{\abs{\hat\alpha}-1} %
		d_i d_j \Delta_{\bar\alpha\beta}(a) \right] = \\
	F_{\bar\alpha\beta}^\beta d_i \Delta_{\bar\alpha\beta}(a^{\abs{\hat\alpha}-1}) %
    F_{\bar\alpha\beta}^\beta d_j \Delta_{\bar\alpha\beta}(a) + %
    F_{\bar\alpha\beta}^\beta \Delta_{\bar\alpha\beta}(a)^{\abs{\hat\alpha}-1} %
    F_{\bar\alpha\beta}^\beta d_i d_j \Delta_{\bar\alpha\beta}(a) = \\%
  \bar\alpha^\dagger_i %
    \Delta_{\beta} (a)^{(\abs{\hat\alpha}-1)(\abs{\bar\alpha}-1)} %
    d_i (\Delta_{\beta} (a)^{\abs{\hat\alpha}-1}) %
    \bar\alpha^\dagger_j %
    \Delta_{\beta} (a)^{\abs{\bar\alpha}-1} %
    d_j \Delta_\beta (a) %
    + %
    \Delta_\beta(a)^{(\abs{\hat\alpha}-1)\abs{\bar\alpha}} %
    (-1) d_j F_{\bar\alpha\beta}^\beta %
    d_i \Delta_{\bar\alpha\beta}(a) = \\%
  (\abs{\hat\alpha}-1)\bar\alpha^\dagger_j%
    \Delta_\beta(a)^{\abs{\hat\alpha}\abs{\bar\alpha} - 2} %
    d_i \Delta_\beta(a) d_j \Delta_\beta (a) %
    + %
    \Delta_\beta(a)^{(\abs{\hat\alpha}-1)\abs{\bar\alpha}} %
    (-1) d_j ( \Delta_\beta(a)^{\abs{\bar\alpha}-1} %
    d_i \Delta_\beta(a) ) = \\%
  (\abs{\hat\alpha}-1)\bar\alpha^\dagger_j%
    \Delta_\beta(a)^{\abs{\alpha} - 2} %
    d_i \Delta_\beta(a) d_j \Delta_\beta (a) %
    + \\%
    \Delta_\beta(a)^{(\abs{\hat\alpha}-1)\abs{\bar\alpha}} %
    (-1) \left( %
    (\abs{\bar\alpha}-1) %
    \Delta_\beta (a)^{\abs{\bar\alpha}-2} %
    d_j \Delta_\beta (a) d_i \Delta_\beta (a) %
    + %
    \Delta_\beta(a)^{\abs{\bar\alpha}-1} %
    d_j d_i \Delta_\beta(a)
    \right) = \\%
  (\abs{\hat\alpha}-1)\alpha_i%
    \Delta_\beta(a)^{\abs{\alpha} - 2} %
    d_i \Delta_\beta(a) d_j \Delta_\beta (a) %
    + \\%
    (\alpha_i-1) %
    \Delta_\beta(a)^{\abs{\alpha}-2} %
    d_i \Delta_\beta (a) d_j \Delta_\beta (a) %
    + %
    \Delta_\beta(a)^{\abs{\alpha}-1} %
    d_i d_j \Delta_\beta(a) = \\%
  (\abs{\alpha}-1)%
    \Delta_\beta(a)^{\abs{\alpha} - 2} %
    d_i \Delta_\beta(a) d_j \Delta_\beta (a) %
    + %
    \Delta_\beta(a)^{\abs{\alpha}-1} %
    d_i d_j \Delta_\beta(a)%
  \end{gather*}
Applying $\alpha^\dagger_I d_{I^{\prime\prime}}$ to the above we obtain a certain expression. It is not hard to see that that exact expression can be obtained from
\begin{equation*}
  \alpha^\dagger_I d_{I \setminus j} %
    ( \Delta_\beta(a)^{\abs{\alpha}-1} d_j \Delta_\beta (a) )
\end{equation*}
by isolating $d_i$, permuting it past $d_{I^{\prime\prime}}$, and applying the Leibniz rule once with respect to $d_i$. This completes the induction, and hence the really not aesthetic proof of this corollary.
\end{proof}
\end{cor}
%
%
\subsection{The Brunside-Witt vectors}
\comm{Add an introduction! Dress Siebeneicher, Elliott, ...}
\begin{thm}\cite{dress1988burnside}
Given a pro-finite group $G$, there is a unique functor
  \[	\bW_G: \bZ-\calg \to \bZ-\calg,\; A \mapsto \bW_G A	\]
%assigning to a commutative ring $A$ a commutative ring $\bW_G A$,
such that after forgetting to sets we have an identity of functors (here evaluated at $A$)
  \[	U \circ \bW_G A = \left [ \prod_{H \leq G} A \right ]^G,	\]
where the right hand side is the $G$-fixed points of the product of $A$ over the set of open subgroups of $G$, with $G$ permuting factors by conjugation, and further such that for every open subgroup $K \in G$, the following map is a natural transformation from $\bW_G$ to the identity functor:
  \[	\phi^A_K: \bW_G A \to A,\]
  \[	x = (x_H) \mapsto \phi^A_K(x) = \sum_{K \lesssim H} \abs{(G/H)^K}(x_H)^{[H:K]},	\]
where the sum is taken over all equivalence classes under conjugation of open subgroups $H \leq G$ with $K$ subconjugate to $H$, i.e. there is a $g \in G$ s. th. $K \leq gHg^{-1}$. By $[H:K]$ we refer to the index of $K$ in $gHg^{-1}$, which is equal to $[G:K]/[G:H]$ and hence independent of $g$. The images of a Brunside-Witt vector under the maps $\phi_K$ are often referred to as its ghost coordinates, and they are readily used to verify certian identities inside the Burnside-Witt ring.
\end{thm}
%
%
\begin{rem}\label{rem_witt_ghost_generators_multiplication}
In our case of interest, the group in question is $\hat\bZ^n$ and in particular abelian (which we will tacitly to be true for $G$ from now on), which simplifies the formula to
\begin{equation}\label{eq_witt_ghost_coordinates}
	\phi_K(x) = \sum_{K \leq H} [G:H](x_H)^{[H:K]}.
\end{equation}
Note also that letting $\omega_H(a) \in \bW_G A$ be the vector with entry $a \in A$ at the open subgroup $H \leq G$ and $0$ elsewhere, for $x \in \bW_G A$, we have
\begin{equation}\label{eq_witt_sum}
	x = \sum_{H \leq G} \omega_H(x_H)
\end{equation}
(in particular this series converges), which one may verify immediately using the above ghost coordinates. Using these generators, the multiplication (cf. \cite[Rem. 4.6]{elliott2006constructing}) can be expressed with the following formula: Given $H,K \leq G$ and $a,b \in A$ we have
\begin{equation}\label{eq_witt_multiplication}
	\omega_H (a) \omega_K (b) = \frac{[G:H][G:K]}{[G : H \cap K]} \omega_{H \cap K}%
		(a^{ [H : H \cap K] } b^{ [K : H \cap K] }).
\end{equation}
\end{rem}
%
%
The Burnside-Witt rings come with extra structure, which we now recollect, following \cite{elliott2006constructing}.\\
\comm{instead of all remarks, just note identification: $\{$ fin. transitive $G$-sets $\} \to \{$ subgroups of $G \}$}
\begin{defn}\label{def_witt_res}
Given a projection $\pr: G \to G/N$ with respect to a normal, open subgroup $N \leq G$ there is a natural transformation of functors of rings, called the restriction map, given by
\[	R_G^{G/N}: \bW_G A \to \bW_{G/N} A,\]
\[	x = (x_H) \mapsto (x_{\pr^{-1}(K)})_K.	\]
\end{defn}
\begin{defn}\label{def_witt_frob}
Given an open subgroup $H \leq G$, there is a natural ring morphism
\[	F_G^H: \bW_G A \to \bW_H A, \]
given by
\[	\omega_K(a) \mapsto ( [G:K]/[H: H \cap K]) \cdot \omega_{H \cap K} (a^{[K : H \cap K]}).	\]
This is called the Frobenius. \comm{[leave out? :]} It is uniquely determined by the above values due to naturality, as the $\omega_K(a)$ form a set of linearly independent topological generators for $A = \bZ$.
\end{defn}
\begin{rem}
We obtain the above formula from the language of $\cite{elliott2006constructing}$ as follows. In the language of frames, the Frobenius is given as
\[	F_G^H: \bW_G A \to \bW_H A	\]
\[	\omega_T(a) \mapsto \sum_{U \in H \backslash T} \omega_U( a^{ [G:H] \abs{U} / \abs{T} } ).\]
Letting $T \in \cF(G)$ correspond to $K \leq G$, taking the $H$-orbits of $T \cong G/K$ is the same as considering the double cosets $H \backslash G / K$, and the stabilizer of an element $hgK$ of an orbit $HgK$ is exactly $H \cap K$, implying that every orbit is isomorphic to the transitive $H$-set $H/(H \cap K)$, hence we have $[G:K]/[H: H \cap K]$ double cosets or $H$-orbits in $G/K$. Using elementary relations for indeces we finally obtain the exponent $[G:H] [H:H \cap K] / [G:K] = [K : H \cap K]$.
\end{rem}
\begin{defn}\label{def_witt_vers}
Let $H$ be an open subgroup of $G$, then the Verschiebung map is the unique additive natural map
	\[	V_H^G : \bW_H A \to \bW_G A \]
given by
	\[ \omega_K (a) \mapsto \omega_K (a) \]
for $K \leq H$, $a \in A$.
\end{defn}
%
%
\begin{defn}\label{def_teichmueller_burnside_witt_vectors}
Another piece of structure is the Teichm\"uller morphism
\begin{gather*}
	\tau_H: A \to \bW_H A,\\%
	a \mapsto \tau_H(a)
\end{gather*}
where $\tau_H(a)_H = a$ and $\tau_H(a)_K = 0$ for $K \not\subset H$, which can immediately be seen to be multiplicative (but not additive) by Eq. \ref{eq_witt_multiplication}.
\end{defn}
%
%
\begin{rem}\label{rem_teichmueller_sum}
With the Teichm\"uller morphisms we can give another interpretation for Eq. \ref{eq_witt_sum}, for we have $\omega_H (a) = V^G_H \tau_H (a) \in \bW_G A$ for any $a \in A$, $H \leq G$, hence given $x \in \bW_G A$ we may write
\begin{equation}\label{eq_witt_teichmueller_sum}
	x = \sum_{H \leq G} V_H^G \tau_H (x_H).
\end{equation}
\end{rem}
%
%
\subsection{Higher de Rahm - Witt Complex}
%
%
\comm{[reorganize this whole beginning...!]}
\begin{thm}\cite[Thm. 3.22]{carlsson2011higher}
Fix an odd prime $p$. Let $A$ be a connective commutative ring spectrum. There is a pro multi-diffenrential graded ring \comm{say: higher/Burnside-Witt Complex?} $TR_q^\alpha(A) \defas TR_q^\alpha(A;p)$ consisting of the following data:
\begin{itemize}
 \item groups $TR^\alpha_q(A) \defas \pi_q ( T_{\sT_p^n}(A)^{L_\alpha} )$ for each $q \in \bZ$, $\alpha \in \cM_n$, where $L_\alpha \defas \alpha^{-1}(\bZ_p) / \bZ_p$,
 \item differentials $d_f: TR^\alpha_*(A) \to TR^\alpha_{*+k}(A)$ for each $f : S^k \to (\sT_p^n)_+$ in $\SHC$,
 \item \colorbox{yellow}{change range of maps for differentials! Use $C_k$!}
 \item restriction operators $R_\alpha \defas R^{(\beta)}_\alpha: TR^{\beta\alpha}_q(A) \to TR^\beta_q(A)$,
 \item Frobenius operators $F^\alpha \defas F^\alpha_{(\beta)}: TR^{\alpha\beta}_q(A) \to TR^\beta_q(A)$, and
 \item Verschiebung operators $V_\alpha \defas V_\alpha^{(\beta)}: TR^\beta_q(A) \to TR^{\alpha\beta}_q(A)$ for each $\alpha,\beta \in \cM_n$,
\end{itemize}
satisfying the following properties and relations:
\begin{itemize}
 \item the tripel $(TR^\alpha_q(A),d,R)$ forms a pro-multi differential graded ring;
 \item the differentials form an exterior algebra generated by $d_i$, $i \in \ind{n}$, where $d_i$ is induced by  $(e_i)_+ \circ \sigma: S^1 \to (\sT^1_p)_+ \to (\sT_p^n)_+$;
 \item the restriction maps are graded ring operators and commute with Frobenius, Verschiebung and differentials;
 \item the Frobenius maps are pro-graded ring operators;
 \item the Verschiebung maps are pro-graded [insert ring]-module operators\\%
    $V_\alpha: (F^\alpha)_* TR_*^\beta(A) \to TR_*^{\alpha\beta}(A)$;
 \item $F^\alpha = id$ and $V_\alpha = id$ for all $\alpha \in \Gl_n(\bZ_p)$;
 \item $R_{\alpha\beta} = R_\alpha R_\beta,$ $F^{\alpha\beta} = F^\beta F^\alpha,$ and $V_{\alpha\beta} = V_\alpha V_\beta$ for all $\alpha, \beta \in \cM_n$;
 \item $F^\alpha V_\beta = \abs{\gcd_{\alpha,\beta}} \cdot V_{[\lcm_{\alpha,\beta} / \alpha]}F^{[\lcm_{\alpha,\beta} / \beta]}$ %
 %$:TR^{[\lcm_{\alpha,\beta} / \beta] \gamma} \to TR^{[\lcm_{\alpha,\beta} / \alpha] \gamma}$
    for all $\alpha, \beta \in \cM_n$;
 \item $d_v F^\alpha = F^\alpha d_{\alpha v}$ and $V_\alpha d_v = d_{\alpha v} V_\alpha$ for all $v \in \bZ^n, \alpha \in \cM_n$;
 \item $F^\alpha d_v V_\beta = d_{\bez_{\alpha}\gcd_{\alpha,\beta}^\dagger v} %
    V_{[\lcm_{\alpha,\beta} / \alpha]} F^{[\lcm_{\alpha,\beta} / \beta]} + %
    V_{[\lcm_{\alpha,\beta} / \alpha]} F^{[\lcm_{\alpha,\beta} / \beta]}%
    d_{\bez_{\beta}\gcd_{\alpha,\beta}^\dagger v}.$
\end{itemize}
[INSERT: map $\lambda$ in zeroeth level from burnside witt ring, relation with frob, $\lambda$ and
differentials, meaning of gcd, lcm, dagger, absolute value aka volume, curly M sub n, remark on
when does the last composition make sense (find in GCD)]
\end{thm}
%
%
\begin{defn}\label{def_bwc}%burnside witt complex
\comm{add definition of burnside witt complex!, i.e. the above}\\
\comm{evaluated on homotopy groups}
\end{defn}
%
%
\begin{defn}\label{def_cmdga}
Let $n \geq 1$. A graded commutative $n$-multi-differential graded algebra $A^*$ is a graded commutative, graded algebra $(A^*)_{* \geq 0}$, together with additive maps $d_i: A^* \to A^{*+1}$ of degree $1$ for all $i \in \ind{n}$, satisfying the following properties:
\begin{itemize}
\item Each $d_i$ is a derivation, i.e. obeys the Leibniz rule (with Koszul sign): Let $x \in A^k, y \in A^l$, then for all $i \in \ind{n}$ we have%
$$d_i (xy) = d_i(x)y + (-1)^{k}xd_i(y);$$
\item The derivations anticommute with each other, i.e. for all $i,j \in \ind{n}$ we have%
$$d_i d_j = - d_j d_i.$$
\end{itemize}
These objects form a category, with morphisms given by maps of graded algebras commuting with the differentials, denoted $\cndga$.
%\\[2ex]
% \comm{QUESTIONS: }
% \comm{name/notation of $\bZ_p$-structure on differentials: seems a bit unnatural, any way to fix this!?}\\
% \comm{more elegant: forget basis; work with a) indexing morphism}\\
% \comm{b) torus homology c) exterior algebra over $\bZ_p$ ?}\\
% \comm{do we have more examples of this then our only one? bicomplex is an example for n=2}\\
\end{defn}
%
%
\begin{prop}\label{prop_higher_de_rahm_complex}
The functor%
$$(-)^0 : \cndga \to \calg$$%
$$A^* \longmapsto A^0,$$%
taking graded commutative n-multi-differential algebras to their zeroeth level, has a left adjoint%
$$\omg{-}{n}{*}: \calg \to \cndga,$$%
$$A \longmapsto \omg{A}{n}{*}$$
given on objects by the higher de-Rham complex, to be defined below.
\begin{proof}
We begin by constructing the higher de-Rham complex. Let $A$ be a commutative ring. We proceed as follows: In analogy to the classical de-Rham complex, we define ($n$ different!) derivations (and their compositions) as free $A$-modules, but without considering the Leibniz rule yet. We take the free graded commutative algebra over the graded module of all compositions of derivations, and finally divide out the Leibniz rule and it's higher analogue for iterated (i.e. compositions of) derivations. Finally we are able to define the differentials and prove the universal property.\\
% \comm{just some loud thking: differentials modelled after Kaehler diff}\\
% \comm{these are modules over the ground ring}\\
% \comm{top. diff are (in their argument) only linear over $\bZ$}\\
% \comm{proof of Fdw relation only for integral torus}\\
% \comm{hence indexing set for differentials is just $\Lambda^* \bZ^n$}\\
% \comm{[note: given input $A$ the differentials will be modules over $A$ but looking}\\
% \comm{[at all $A$, the structures are just over $\bZ$ or $\bZ_p$; rest governed by $F,V$,...]}\\
% \comm{[so yes $A$-modules, the construction in that sense is fine, you have $A$ in the bottom degree!]}\\
In the following, all tensor products are taken over the integers, i.e. $\otimes \coloneqq \otimes_{\bZ}$. Consider the inclusion of $A$-modules $A \otimes \bZ \to A \otimes A$, $a\otimes r \longmapsto a \otimes (r \cdot 1)$, where $A$ is acting on the left factor and $i \in A$ is the unit in $A$. Taking the cokernel yields a free A-module with elements denoted as $a\otimes b \eqqcolon a \del (b)$ such that the symbol $a \del (b)$ is bilinear in $(a,b)$ and $A$-linear in $a$, and further vanishes for $b \in \bZ$. Observe that this corrensponds to Kaehler differentials, without the Leibniz rule. Let
$$\tilde{D}^k \coloneqq (A \otimes A / A \otimes \bZ) ^ { I_{n,k} },$$
where $I_{n,k}$ is the set of injective maps $\ind{k} \to \ind{n}$. The collection $(D_k)_k$ is meant to model the space of $n$ different (alternating) differentials and their composites, or to be precise: composites of $k$ pairwise different differentials. We denote elements of $\tilde{D}^k$ living in the summand corresponding to $\alpha: \k \to \n$ as
\[a \del_\alpha (b) = a \del_{\alpha(k)} \ldots \del_{\alpha(1)} (b)\]%
for $a,b \in A$. Note that we choose to respect the order of composition, so we assume the indices ordered from right to left, hence they should be read from right to left.\\%
We define an $A$-linear action of $\Sigma_k = \{f: \ind{k} \to \ind{k} \with f \; \mathrm{bijective} \}$ on $\tilde{D}^k$ by setting%
$$\sigma \del_\alpha (a) = \sgn(\sigma) \cdot \del_{\alpha \sigma} (a)$$
and extending $A$-linearly, thus obtaining the $A$-module $D^k \coloneqq \tilde{D}^k/\Sigma_k$. This step should reflect the fact that differentials alternate with each other. Considering (the class of) some $\del_\alpha a \in D^k$ for $a \in A$, $\alpha \in I_{n,k}$ we will assume $\alpha$ to be strictly monotonously increasing unless noted otherwise.\\
We proceed by considering the graded module
\begin{equation*}
D \coloneqq \bigoplus_{k=1}^{n} D^k
\end{equation*}
where $D^k$ lives in grade $k$, and consider the free, graded commutative, graded algebra over $A$ on $D$, denoted $(\bigwedge D)^*$. It may be given as the free graded tensor algebra
\begin{equation*}
	T (D) = \sum_{i \geq 0} D^{\otimes i}
\end{equation*}
with multiplication given by concatenation, divided by the ideal generated by elements of the form
\begin{equation*}
	x \otimes y - (-1)^{\abs{x}\abs{y}} y \otimes x
\end{equation*}
for all $x,y \in D$. We will denote the class of an element $x \otimes y$ in $\bigwedge D$ as $x \wedge y$. We recall that the grading of an element $x = x_1 \wedge \ldots \wedge x_k \in \bigwedge D$ with $x_i \in D^{\abs{x_i}}$ for $i \in \ind{k}$ is given as the sum of the gradings of the factors:
\begin{equation*}
	\abs{x} = \sum_{i=1}^k \abs{x_i}.
\end{equation*}
We have a graded commutative ring, but in order to be able to define derivations $d_i: \bigwedge D ^* \to (\bigwedge D)^{*+1}$ for $i \in \ind{n}$ we must make sure that the relations implied by the Leibniz rule are valid. Hence we divide out the graded ideal $\mathcal{I}$ generated by the following elements: For all $x,y \in A$, $\alpha: \k \to \n$ strictly monotonously increasing we set $C \coloneqq \im \alpha \setminus B$ for $B \subseteq \im \alpha$ and take
\[ l(\alpha,x,y) \defas \del_\alpha(xy) - \sum_{B \subseteq \im \alpha} \sgn(\chi_{B,C}) %
  \del_B (x) \wedge \del_C (y) \in D^k \oplus ( \bigoplus_i D^i \wedge D^{k-i} ) \]
Note that we choose representatives with ordered indices, i.e. $\del_B= \del_{j_m} \cdots \del_{j_1}$ for $B = \{ j_1, \ldots, j_m \}$ with $j_1 < \ldots < j_m$, and analogously for $C$. Here the symbol $\chi_{B,C}$ refers to the shuffle permutation of $\im \alpha$ which orders $C$ before $B$; More precisely, let $\im \alpha = \{ i_1 \ldots i_k \}$ with $i_1 < \ldots < i_k$, $B = \{j_1 \ldots j_m \}$, $C = \{ l_1 \ldots l_{k-m} \}$ with $j_1 < \ldots < j_m$, $l_1 < \ldots < l_{k-m}$. Then $\chi_{B,C}$ permutes the tupel $(i_k \ldots i_1)$ to $(j_m \ldots j_1 \; l_{k-m} \ldots l_1)$.\\
We denote the quotient as%
\[ \omgn^* \coloneqq \bigmod {\left(\bigwedge D\right)} {\mathcal{I}} ^* \]%
and will subsequently drop the dimension and the ring from the notation unless there is the possibility of ambiguity.\\
Now, for $i \in \ind{n}$, which we fix, we may define additive $d_i: \bigwedge D^* \to \Omega^{*+1} $ and show that these descend to derivations ${d_i: \Omega^* \to \Omega^{*+1}}$. We proceed to define $d_i: \prod_{i=1}^k D \to \Omega^*$ using induction on $k$ and show first that this descends to $d_i: \bigwedge D^* \to \Omega^{*+1}$.\\
Since $d_i$ will only be additive, but not $A$-linear, for the empty product we set for $a \in A$:
\[
  d_i (a) = \del_i (a) \in D^1.
\]
For $a \del_\alpha (b) \in D^k$ we set
\[ d_i (a \del_\alpha (b)) \coloneqq  \del_i (a) \wedge \del_\alpha (b) + a \del_i \del_\alpha (b) \in D^1 \wedge D^k \oplus D^{k+1}, \]
where the second summand is defined to be zero if $i \in \im \alpha$. Both summands are $\bZ$-bilinear in $a$ and $b$ and vanish for $b \in \bZ$. Furthermore, the map is equivariant with respect to the $\Sigma_k$-action (acting on $\alpha$ on both sides). Hence this is well-defined and may be extended linearly. Note also that if $a \in \bZ$ (in particular if $a = 1$), the first summand vanishes.
\\
For a product with $k>1$ factors, let $x_i \in D^{\abs{x_i}}$, for $i \in \ind{k}$. Then $ x \defas ( x_1 , \ldots , x_k ) $ is sent to
    \[ d_i (x) \coloneqq%
    d_i (x_1) \wedge x_2 \wedge \ldots \wedge x_k + %
    (-1)^{\abs{x_1}} x_1 \wedge d_i (x_2, \ldots, x_k). \]%
Using the induction beginning and step we see that this is well-defined. Note also that the degree of each summand is indeed equal to the degree of $\abs{x}$ increased by one. Again, note that we only extend $\bZ$-linearly, so we shall define $d_i$ on formal products $a.x$ for $a \in A, \; x = (x_1 , \ldots , x_k) \in \prod_k D$. We set
\[
  d_i (a.x) = \del_i(a) \wedge %
  x_1 \wedge \ldots \wedge x_k + a \wedge d_i(x)
\]
and argue that this is well defined by showing that the definition is balanced with respect to $A$, i.e. descends to the tensor product (over $A$).\\
For the relations of the tensor product, the definition is multilinear (over $\bZ$) by definition and induction. To see that it respects the relation for graded commutativity, we need to take a closer look at the definition. Resolving the recursion, we arrive at the following formula for $x_1, \ldots, x_k \in D$:
\begin{equation*}
  d_i (x_1, \ldots , x_k) = %
  \sum_{i=1}^k %
  \left( \prod_{j=1}^{i-1} (-1)^{\abs{x_j}} \right) %
  x_1 \wedge \ldots \wedge d_i (x_i) %
  \wedge \ldots \wedge x_k,
\end{equation*}
and after staring at it for a moment one realizes that this is indeed alternating in the input, i.e. interchanging the position of say $x_l$ and $x_{l+1}$ leads to multiplication by the factor $(-1)^{\abs{x_l}\abs{x_{l+1}}}$.\\
The definition is balanced in $A$ by the following argument: For $a,b,c \in A$ we have
\begin{gather*}
  d_i ( a . (b \del_\alpha (c)) - %
    (ab) \del_\alpha (c) ) = \\ %
  \del_i(a) \wedge b \del_\alpha(c) + %
    a \wedge ( \del_i(b) \wedge \del_\alpha (c) + %
      b \del_i \del_\alpha (c) ) - %
    \del_i(ab) \wedge \del_\alpha (c) - %
    ab \del_i \del_\alpha (c) = \\%
  \del_i (a) \wedge b \wedge \del_\alpha (c) + %
    a \wedge \del_i (b) \wedge \del_\alpha (c) - %
    \del_i (ab) \wedge \del_\alpha (c) \in \cI,%
\end{gather*}
and
\begin{gather*}
  d_i(a.b - ab) = \del_i (a) \wedge b + a \wedge \del_i (b) - \del_i (ab) \in \cI
\end{gather*}
hence the above terms vanish in $\Omega^*$. As $d_i$ is alternating in its input, it suffices to show that it is $A$-linear, say, in the first variable. Due to the definition of $d_i$ (it satisfies the Leibniz rule) we see that $A$-linearity in the first variable follows from the above discussion: For $x_1 , \ldots , x_k \in D$, $a \in A$ we have
\begin{gather*}
  d_i (a. (x_1, \ldots, x_k) - (a x_1, x_2, \ldots, x_k)) = %
  d_i (a.x_1 - a x_1, x_2, \ldots , x_k) = \\ %
  d_i (a.x_1 - a x_1) \wedge x_2 \wedge \ldots \wedge x_k + (-1)^{\abs{x_1}} (a.x_1 - a x_1) \wedge d_i (x_2, \ldots , x_k) = 0 \in \Omega^* %
\end{gather*}
and hence $d_i$ indeed descends to a map $\bigwedge D ^* \to \Omega ^ {*+1}$.
\\
We show next that this also descends to a morphism $d_i: \Omega^* \to \Omega^{*+1}$. We have to check that for $x \in \mathcal{I}^*$ we have $d_i(x) \in \mathcal{I}^{*+1}$. Let $x,y \in A$, $\alpha \in I_{n,k}$ strictly monotonously increasing. We first show that $d_i ( l(x,y,\alpha) ) = \delta l(x,y,\tilde \alpha)$ for some $\delta \in \{1,-1\}$, where $\tilde \alpha: \ind{k+1} \to \n$ is the strictly monotonously increasing map with $\im \tilde \alpha = \im \alpha \cup \{i\}$. Note that we may assume $i \notin \im \alpha$, since otherwise we have $d_i ( l(x,y,\alpha) ) = 0 \in \cI^{*+1}$ by definition of $d_i$.\\
Recall that for $B \subseteq \im \alpha$ we write $C \defas \im \alpha \setminus B$. We compute:
    \[ d_i ( l(x,y,\alpha) ) =  d_i \left( \del_\alpha (xy) - \sum\limits_{B \subset%
    \im \alpha} \sgn(\chi_{B,C}) \del_B x \del_C y \right) = \]%
    %
    \[ \del_i \del_\alpha (xy) - \sum\limits_{B \subseteq \im \alpha} \sgn(\chi_{B,C})%
    d_i ( \del_B x \del_C y ) = \]%
    %
    \[ \del_i \del_\alpha (xy) - \sum\limits_{B \subseteq \im \alpha} \sgn(\chi_{B,C})%
    ( \del_i \del_B x \del_C y + (-1)^{\abs{B}} \del_B x \del_i \del_C y ). \]
Observe that all summands of $l(x,y,\tilde \alpha)$ appear, at least up to signs and permutations of differentials:
    \[ l(x,y,\tilde \alpha) = \del_{\tilde \alpha} (xy) - \sum_{B \subseteq \im \tilde \alpha} \sgn (\chi_{B,C})%
    \del_B x \del_C y. \]
Comparing the first two summands, we obtain
    \[ \del_{\tilde \alpha} (xy) = %
    (-1)^{\abs{\{ j \in \im \alpha \with j > i \}} } \del_i\del_\alpha (xy). \]
Hence it suffices to show that every other pair of summands also differs by this sign after permuting the indices so that they match. Let $N(\sigma)$ denote the number of inversions of a permutation $\sigma$. We have two cases to consider. Firstly, we have
    \[ \del_i \del_B x \del_C y = %
    (-1)^{ \{j \in B \with j > i\} } \del_{ B \cup \{i\} } x \del_C y,\]
so we want to show%
    \[ (-1)^{\abs{\{ j \in \im \alpha \with j > i \}} } \sgn(\chi_{B,C}) %
    (-1)^{\abs{\{ j \in B \with j > i \}} } = \sgn(\chi_{B \cup \{i\},C}),\]%
but
    \[ N(\chi_{B \cup \{i\},C}) = N(\chi_{B,C}) + %
    \abs{ \{ j \in C \with j > i\} }, \]%
and with%
    \[(-1)^{\abs{\{ j \in \im \alpha \with j > i \}} }  (-1)^{ \abs{ %
    \{ j \in B \with j > i \} } } = (-1)^{ \abs{ \{j \in C \with j > i\} } }\]%
(recall that $C = \im \alpha \setminus B$) we obtain equality. Secondly, we have%
    \[\del_B x \del_i \del_C y = (-1)^{ \abs{ \{j \in C \with j > i\} } }%
    \del_B x \del_{ C \cup \{i\} } y, \]
hence we are looking to show that%
    \[ (-1)^{\abs{\{ j \in \im \alpha \with j > i \}} } \sgn(\chi_{B,C})%
    (-1)^{\abs{B}} (-1)^{ \abs{ \{j \in C \with j > i\} } } = %
    \sgn( \chi_{ B, C \cup \{i\} } ), \]
which holds, as%
    \[ (-1)^{\abs{\{ j \in \im \alpha \with j > i \}} } %
    (-1)^{\abs{B}} (-1)^{ \abs{ \{j \in C \with j > i\} } } =%
    (-1)^{ \{ j \in B \with j < i \} } \]%
and%
    \[ N(\chi_{ B, C \cup \{i\} }) = N(\chi_{B,C}) + %
    \abs{ \{j \in B \with j < i\} }. \]
Hence we have shown that%
    \[ d_i ( l(x,y,\alpha) ) = (-1)^{ \{j \in \im \alpha \with j > i \} }%
    l(x,y,\tilde \alpha). \]
As $d_i$ is not multiplicative, but is additive, it now suffices to check that for all $r \in (\bigwedge D)^k$ and all generators $x \in \mathcal{I}^*$ we have $d_i(rx) \in \mathcal{I}^{k+*+1}$, but by definition of $d_i$ we have%
    \[ d_i(rx) = d_i(r) x + (-1)^k r d_i(x) \in \mathcal{I}, \]
since $\mathcal{I}$ is an ideal, and the claim follows: we have $d_i:\Omega^* \to \Omega^{*+1}$ for all $i \in \n$.\\
Finally we show that this construction is left-adjoint to evaluation at zero. From this, functoriality follows formally. Let $A \in \calg$, $B^* \in \cndga$, $\phi: A \to B^0$ a map of rings. We prove existence and uniqueness of a morphism of graded algebras $\phi^*: \Omega^*_{A,n} \to B^*$ with $\phi^0 = \phi$ and $\phi^{*+1} d_i = d_i \phi^*$ for all $i \in \n$. Following tradition we start with uniqueness: Assume we have a map as above. Then we have
    \[ \phi(a \del_{\alpha_1} (b_1) \wedge \ldots \wedge \del_{\alpha_m} (b_m)) = \]
    \[ \phi(a) \phi (\del_{\alpha_1} (b_1)) \ldots \phi(\del_{\alpha_m} (b_m)) = \]
    \[ \phi(a) d_{\alpha_1} (\phi(b_1)) \ldots d_{\alpha_m} (\phi(b_m)), \]
hence by using that $\phi$ is a ring homomorphism and that it commutes with the differentials, we see that such a morphism is uniquely determined by its values on $A$.\\ For the construction, consider%
    \[ \phi^k: \tilde D^k = (A \otimes A / A \otimes \bZ)^{I_{n,k}} %
    \to B^k, \; a \del_\alpha (b) \mapsto %
    \phi(a) d_\alpha (\phi(b)). \]
This is a well-defined morphism of $A$-modules, where $A$ acts on $B^k$ via the pullback $\phi^*:B^0-\mathrm{mod} \to A-\mathrm{mod}$, and constant on $\Sigma_k$-orbits, hence we get a map of $A$-modules%
    \[ \phi^*: D^* = \bigoplus_{i=1}^n D^i \to B^* \]
which in turn lets us define a ring homomorphism
    \[ \phi ^*: (\bigwedge D)^* \to B^*, %
    a \del_{\alpha_1} (b_1) \wedge \ldots \wedge \del_{\alpha_m} (b_m) \mapsto%
    \phi(a) d_{\alpha_1} (\phi(b_1)) \ldots d_{\alpha_m} (\phi(b_m)), \]
as the target is graded commutative and the source is the free graded commutative graded ring on $D^*$.
By Lemma \ref{lem_higher_leibniz_rel}, we have $\mathcal{I} \subseteq \ker \phi$, so we get an induced ring homomorphism%
\[\phi^*: \Omega^* = \Omega^*_{A,n} \to B^*.\]
Let us check that this commutes with the differentials. Let $i \in \n$. We proceed again by induction over the factors in $\Omega^*$: For $a,b \in A$, $\alpha \in I_{n,k}$ we have
    \[ d_i \phi^k ( a \del_\alpha (b) ) = d_i (\phi(a) d_\alpha(\phi(b)) ) = %
    d_i (\phi(a)) d_\alpha(\phi(b)) + \phi(a) d_i d_\alpha (\phi(b)), \]
and
    \[ \phi^{k+1} d_i (a \del_\alpha (b)) = %
    \phi^{k+1} (\del_i (a) \wedge \del_\alpha (b) + a \del_i \del_\alpha (b) ) = %
    d_i (\phi(a)) d_\alpha(\phi(b)) + \phi(a) d_i d_\alpha (\phi(b)). \]
Now let $a_j, b_j \in A$, $\alpha_j \in I_{n,k_j}$ for all $j \in \ind{m}$.%
Then%
    \[ d_i \phi^* ( a_1 \del_{\alpha_1} (b_1) \wedge \ldots \wedge %
    a_m \del_{\alpha_m} (b_m) ) = \]%
    %
    \[d_i ( \phi^{k_1}( a_1 \del_{\alpha_1} (b_1) ) \wedge \ldots \wedge %
    \phi^{k_m} ( a_m \del_{\alpha_m} (b_m) ) ) = \]%
    %
    \[d_i ( \phi^{k_1}( a_1 \del_{\alpha_1} (b_1) ) ) \wedge %
    \phi^{k_2}( a_2 \del_{\alpha_2} (b_2) ) \wedge \ldots \wedge %
    \phi^{k_m}( a_m \del_{\alpha_m} (b_m) ) + \]%
    \[ + (-1)^{k_1} \phi^{k_1}( a_1 \del_{\alpha_1} (b_1) ) \wedge %
    d_i ( \phi^{k_2}( a_2 \del_{\alpha_2} (b_2) ) \wedge \ldots \wedge %
    \phi^{k_m}( a_m \del_{\alpha_m} (b_m) ) ),
    \]
while (note that $*$ in the following is just a placeholder and may vary)
    \[
    \phi^{*} d_i ( a_1 \del_{\alpha_1} (b_1) \wedge \ldots \wedge %
    a_m \del_{\alpha_m} (b_m) ) = \]%
    %
    \[ \phi^{*} ( d_i ( a_1 \del_{\alpha_1} (b_1) ) \wedge a_2 \del_{\alpha_2} (b_2) \wedge \ldots \wedge a_m \del_{\alpha_m} (b_m) + \]%
    \[ + (-1)^{k_1} a_1 \del_{\alpha_1} (b_1) \wedge d_i (a_2 \del_{\alpha_2} (b_2) %
    \wedge \ldots \wedge a_m \del_{\alpha_m} (b_m)) ) = \]%
    %
    \[\phi^{k_1+1} (d_i ( a_1 \del_{\alpha_1} (b_1) ) ) \wedge %
    \phi^{k_2}( a_2 \del_{\alpha_2} (b_2) ) \wedge \ldots \wedge %
    \phi^{k_m}( a_m \del_{\alpha_m} (b_m) ) + \]%
    \[ + (-1)^{k_1} \phi^{k_1}( a_1 \del_{\alpha_1} (b_1) ) \wedge \phi^* d_i (a_2 \del_{\alpha_2} (b_2) \wedge \ldots \wedge a_m \del_{\alpha_m} (b_m)), \]
and again using the induction beginning as well as step we see that $\phi$ and $d_i$ commute, proving existence and hence the proposition.
\end{proof}
\end{prop}
%
%
\begin{lem}\label{lem_higher_leibniz_rel}
Let $A^* \in \cndga$, $\alpha:\k \to \n$ strictly monotonously increasing, and $x,y \in A^*$. For $B \subseteq \im \alpha$, set $C \defas \im \alpha \setminus B$. Then the following formula holds:%
    \[ d_\alpha (xy) = \sum_{B \subseteq \im \alpha} \sgn( \chi_{B,C} ) (-1)^{\abs{x}\abs{C}} d_B x d_C y. \]
\begin{proof}
We proceed by induction on $k$: Let $k \in \n$, then, as $d_k$ is a derivation, we have
\[ d_k(xy) = d_k(x) \, y + (-1)^{\abs{x} \cdot 1} x \, d_k(y). \]
Let $\alpha: \k \to \n$ as above, $\im \alpha = \{ \alpha_1 \ldots \alpha_k \}$, $\alpha_1 \less \ldots \less \alpha_k$, and $\alpha^\prime \defas \alpha|_{\k \setminus \{1\}}:\{2,\ldots,k\} \to \n$. We compute
\begin{gather*}
  d_\alpha (xy) = d_{\alpha^\prime}\,d_{\alpha_1}(xy) =%
    d_{\alpha^\prime}( d_{\alpha_1}(x) y + (-1)^{\abs{x}} x \, d_{\alpha_1}(y) ) =\\[.3em]
  \sum_{B^\prime \subseteq \im \alpha^\prime} \sgn(\chi_{B^\prime,C^\prime}) %
    (-1)^{ (\abs{x}+1) \abs{C^\prime} } d_{B^\prime} d_{\alpha_1}(x)d_{C^\prime}(y) \;\; + \\%
  (-1)^{\abs{x}} \sum_{B^\prime \subseteq \im \alpha^\prime}%
    \sgn(\chi_{B^\prime,C^\prime}) (-1)^{ \abs{x} \abs{C^\prime} } %
    d_{B^\prime}(x) \, d_{C^\prime}d_{\alpha_1}(y) = \\ %
  \sum_{B^\prime \subseteq \im \alpha^\prime} \sgn(\chi_{B^\prime,C^\prime}) %
    (-1)^{\abs{C^\prime}}(-1)^{ \abs{x} \abs{C^\prime} } %
    d_{B^\prime \cup \{\alpha_1\} }(x) d_{C^\prime}(y) \;\; + \\%
  \sum_{B^\prime \subseteq \im \alpha^\prime} \sgn(\chi_{B^\prime,C^\prime}) %
    (-1)^{\abs{x}(\abs{C^\prime}+1)} %
    d_{B^\prime}(x) d_{C^\prime \cup \{\alpha_1\}}(y) = \\%
  \sum_{B \subseteq \im \alpha} \sgn( \chi_{B,C} ) (-1)^{\abs{x}\abs{C}} d_B (x) d_C (y).
\end{gather*}
The first equalities are elementary manipulations and the induction hypothesis. For the last equality, we collected the two sums, noting that %
  $\sgn(\chi_{B^\prime,C^\prime})(-1)^{\abs{C^\prime}} = %
    \sgn(\chi_{B^\prime \cup \{\alpha_1\},C^\prime})$.
\end{proof}
\end{lem}
%
%
\begin{lem}\label{lem_freyds_adjoint_functor}\cite[V.6 Theorem 1]{mac1978categories}
Let $C$ be a small complete (i.e. all limits over small indexing categories exist) category. Then $C$ has an initial object if and only if it satisfies the solution set condition: There exists a set $I$ and an $I$-indexed family $(x_i)_{i \in I}$ in $C$ such that for every $c \in C$ there is an $i \in I$ and a morphism $x_i \to c$.
\end{lem}
%
%
\begin{thm}\label{thm_existence_initial_object}
There is an initial object in the category of Burnside-Witt complexes over $A$, called the de Rham-Burnside-Witt complex, and denoted $\cW_\cdot \Omega_{A,n}^*$.
\end{thm}
We follow the strategy of the proof of Theorem A in \cite{hesselholt2004rham}. Due to Freyd's adjoint functor theorem (cf. Lemma \ref{lem_freyds_adjoint_functor}), it suffices to show that we have a map%
\[ \tilde{\Omega}_{W_{\Cdot} A}^* \to E^*_{\Cdot} \]
out of a fixed object into any Burnside-Witt complex $E$ (over $A$), whose image is a Burnside-Witt subcomplex, for considering the isomorphism classes of these subcomplexes for varying $E$ we note that these form a set, as they are all quotients of $\tilde{\Omega}_{W_{\Cdot} A}$, giving the set and the morphisms (a subcomplex of every Burnside-Witt complex is represented) required by the solution set condition.\\
To this end, we extend the construction of the multi-differential de Rham complex $\Omega^*_{\Cdot} \defas \Omega^*_{W_{\Cdot} A}$ based on the Burnside Witt vectors to incorporate the Verschiebung operators. The structure of Burnside-Witt complexes will then guarantee that the image is a sub-complex. We begin with
%
%
\begin{defn}\label{def_admissible_words}
Consider the alphabet
\begin{equation*}
\cA \defas \{\cV_\alpha^{\beta\alpha},\; x_\gamma \with x \in \Omega^*_{\gamma}, \gamma \in \cM_n, * \geq 0, \alpha, \beta \in \cM_n,\},
\end{equation*}
where we abbreviate $x_\gamma \defas (x,\gamma)$ and $\cV_\alpha^{\beta\alpha} \defas (\cV,\alpha,\beta\alpha)$, and the monoid of all words (or strings) on this alphabet $\cS \defas \bigcup_{i \geq 0} \cA^i$ under concatenation, with unit the empty word $\varnothing \to \cA$. Here we attached the isogeny $\alpha$ to an $x \in \Omega^*_{\alpha}$ in order to distinguish elements corresponding to different isogenies $\alpha \neq \beta$ with $L_\alpha = L_\beta$ (and subsequently $W_\alpha A = W_{L_\alpha} A = W_{L_\beta} A = W_\beta A$).\\
We define a subset of admissible words together with a map
\begin{equation*}
  \cS_{\mathrm{adm}} \subseteq \cS,\;\; %
  \theta: \cS_{\mathrm{adm}} \to \cM_n,
\end{equation*}
where the former will pick out the sequences of symbols that we may interpret sensibly in our context, while the latter will indicate where they are to be interpreted. The definition is done according to the following rules:
\begin{itemize}
\item $x \in \Omega^*_{\alpha} \Rightarrow x_\alpha \in \cS_{\mathrm{adm}}$, $\theta(x_\alpha) \coloneqq \alpha$
\item $w,w^\prime \in \cS_{\mathrm{adm}}$, $\theta(w) = \theta(w^\prime) \Rightarrow ww^\prime \in \cS_{\mathrm{adm}}$, %
    $\theta(ww^\prime) \defas \theta(w)$
\item $w \in \cS_{\mathrm{adm}}, \beta \in \cM_n, \alpha \defas \theta(w) \Rightarrow \cV_\alpha^{\beta\alpha}w \in \cS_{\mathrm{adm}}$, %
      $\theta(\cV_\alpha^{\beta\alpha}w) \defas \beta\alpha$
\end{itemize}
Here, $ww^\prime$ is the concatenation of $w$ and $w^\prime$, and we define $\cS_\mathrm{adm}$ to be the set of all words that may be obtained by a finite number of applications of the above rules. We are capturing all of $\Omega^*_\cdot$, concatenation is a model for multiplication, and we are able to apply the Verschiebung operators, which really is our goal.

Proving that this is well-defined is a bit complicated. We formulate the following statements, which will let us show that $\theta$ and hence $\cS_{\mathrm{adm}}$ are well-defined, by induction over the length of words.  The complicated part is that we have to do an involved induction. We denote the length of a word $w \in \cS$ by $l(w)$, meaning the number of letters in $w$, or in symbols: $w \in \cA^i \Rightarrow l(w) = i$.
For all $n \geq 2$ and $m \geq 1$ we let
\begin{itemize}
\item[] \emph{A(n)}: For all $w \in \cS_{\mathrm{adm}}$ with $l(w) \leq n$, if we can write
	\begin{equation*}
	w = \cV^{\beta\alpha}_\alpha w^\prime,
	\end{equation*}
	then we may find 	$w^{\prime\prime}, w^{\prime\prime\prime} \in \cS_{\mathrm{adm}}, \theta(w^{\prime\prime}) = \alpha, \theta(w^{\prime\prime\prime}) = \beta\alpha$ (or $w^{\prime\prime\prime}$ is empty) such that
	\begin{equation*}
	w = \cV_\alpha^{\beta\alpha} w^{\prime\prime} w^{\prime\prime\prime}.
	\end{equation*}
\item[] \emph{B(n)}: For all $w = uv \in \cS_{\mathrm{adm}}$ with $l(w) \leq n$ we have that if $u$ is admissible and $\theta(u) = \alpha$, then also $\theta(w) = \alpha$.
\item[] \emph{WD(m)}: For all $w \in \cS_{\mathrm{adm}}$ with $l(w) \leq m$ we have that $\theta(w)$ is well-defined, i.e. all possible ways of assigning a value $\theta(w) \in \cM_n$ to $w$ coincide.
\end{itemize}
\end{defn}
%
%
\begin{lem}\label{lem_theta_well_defined}
The statements \emph{A(n)}, \emph{B(n)}, and \emph{WD(m)} are true for all $n \geq 2, m \geq 1$.
\begin{proof}
We first prove that $\mathrm{WD}(n)$ $\Rightarrow$ $\mathrm{A}(n)$ and that $(\mathrm{WD}(n), \mathrm{A}(n)) \Rightarrow \mathrm{B}(n)$ for all $n \geq 2$, proceed to prove $\mathrm{WD}(1)$ as well as $\mathrm{WD}(2)$, and finally prove that $\mathrm{WD}(n), \mathrm{A}(n)$, and $\mathrm{B}(n)$ together imply $\mathrm{WD}(n+1)$ for $n \geq 2$.

Let $n \geq 2$ and assume that $\theta$ is well-defined on all admissible words of length at most $n$. We prove $\mathrm{A}(n)$ by induction over $n = l(w)$ with $w = \cV^{\beta\alpha}_\alpha w^\prime \in \cS_{\mathrm{adm}}$.\\
Assuming the case $n = 2$ we have $w^\prime \in \cA^1 = \cA$. If $w^\prime = \cV^{\gamma\delta}_\delta$ for some $\gamma,\delta \in \cM_n$, $w = \cV^{\beta\alpha}_\alpha \cV^{\gamma\delta}_\delta$ would not be admissible, hence $w^\prime = x_\gamma$ for some $\gamma \in \cM_n$. But since $w$ is admissible, we must in particular have $\gamma = \alpha$, and we may set $w^{\prime\prime} \defas x_\gamma$ and let $w^{\prime\prime\prime}$ be empty.\\
Now let $n = l(w) > 2$. There are two cases to consider, corresponding to the second and third rule of defining the set of admissible words. Let $w = xy$ for some $x,y \in S_{\mathrm{adm}}$ with $\theta(x) = \theta(y)$. We have that $x = \cV^{\beta\alpha}_\alpha x^\prime$ for some $x^\prime \in \cS$, and since $y$ is not empty, $l(x) < l(w) = n$ and we may apply the induction hypothesis $\mathrm{A}(n-1)$ and obtain $x^{\prime\prime},x^{\prime\prime\prime} \in \cS_{\mathrm{adm}}$ with $\theta(x^{\prime\prime}) = \alpha$, $\theta(x^{\prime\prime\prime}) = \beta\alpha$ (or $x^{\prime\prime\prime}$ empty) and $x = \cV^{\beta\alpha}_\alpha x^{\prime\prime}x^{\prime\prime\prime}$. Since $\mathrm{WD}(n)$ holds, we may conclude that $\beta\alpha = \theta(x) = \theta(y)$ and may hence set $w^{\prime\prime} \defas x^{\prime\prime}$ and $w^{\prime\prime\prime} \defas x^{\prime\prime\prime} y$. Finally, let $w = \cV^{\gamma\delta}_\delta z$ with $z \in S_{\mathrm{adm}}, \theta(z) = \gamma\delta$. But then $\delta = \alpha, \gamma = \beta$ and we may set $w^{\prime\prime} \defas z$ and leave $w^{\prime\prime\prime}$ empty.

Assuming well-definedness for words of length up to $n$ as well as property $mathrm{A}(n)$, we proceed to prove the validity of $B(n)$.\\
Let $w = uv \in \cS_{\mathrm{adm}}$, $u \in \cS_{\mathrm{adm}}$ and $\theta(u) = \alpha$. We want to show that $\theta(w) = \alpha$ hols as well. Assume first that $l(w) = 2$, then $u = x_\gamma$ and, as above, we must have $w = y_\gamma$. Now assume $l(w) = n$ for some $n > 2$. Again, we differentiate by the two rules: Let $w = xy$ for $x,y \in \cS_\mathrm{adm}$ with $\theta(x) = \theta(y) \eqqcolon \gamma$. Since we assume $\mathrm{WD}(n)$ to be true, we may conclude $\theta(w) = \theta(x)$. Now there are two possibilities regarding the length of $x$: Either $l(u) \leq l(x)$, or $l(x) < l(u)$. In the first case, as $y$ is admissible, it is not empty, hence $l(x) < l(w) = n$ and we may apply $\mathrm{B}(n-1)$ to $x$ to conclude that $\alpha = \theta(u) = \theta(x) = \theta(w)$. For the second case, we may again apply $\mathrm{B}(n-1)$, but this time to $u$, and conclude that $\theta(w) = \theta(x) = \theta(u) = \alpha$. For the other rule, we assume $w = \cV_\gamma^{\delta\gamma} w^\prime$ for some $w^\prime \in \cS_{\mathrm{adm}}$ with $\theta(w^\prime) = \delta\gamma$. By well-definedness we have $\theta(w) = \delta$. We may write $u = \cV_\gamma^{\delta\gamma} u^\prime$ for some $u^\prime \in \cS$, and conclude by $\mathrm{A}(n)$ that there are $u^{\dprime},u^{\tprime}\cS_{\mathrm{adm}}$ with $\theta(u^{\dprime}) = \gamma, \; \theta(u^{\tprime}) = \delta\gamma$ (or $u^{\tprime}$ is empty). Arguing with $\mathrm{WD}(n)$ we see that $\alpha = \theta(u) = \delta\gamma = \theta(w)$, which concludes the proof of $\mathrm{B}(n)$.

Next, we set out to prove $\mathrm{WD}(1)$ and $\mathrm{WD}(2)$. This is fairly simple, as words of length one consist of letters $x_\gamma = (x,\gamma)$ and $(x,\gamma) \neq (x,\delta)$ for $\delta \neq \gamma$. For words $w = ab$ of length two with $a,b \in \cA$, assuming $b=\cV_\alpha^\beta\alpha$ for some $\alpha,\beta \in \cM_n$ leads to a contradiction to $w$ being admissible for any choice of $a \in \cA$, hence $b = x_\gamma$ for some $\gamma \in \cM_n$. If $a = \cV_\alpha^{\beta\alpha}$, we have, as before, that $\gamma = \alpha$, as $w$ is admissible. If $a = y_\delta$, for $w$ to be admissible we must have $\delta = \gamma$, which concludes $\mathrm{WD(2)}$.

For the third part we assume $\mathrm{WD}(n-1)$ for $n \geq 2$ and prove $\mathrm{WD}(n)$. By the above considerations, we may also assume $\mathrm{A}(n-1)$ as well as $\mathrm{B}(n-1)$. There are two cases to consider in which an ambiguity may arise: That an admissible word is obtained by an application of rule number two and three, or by two (possibly different) applications of rule number two. We shall show that both cases result in coinciding definitions of $\theta$ for that word.\\
Let $w \in \cS_\mathrm{adm}$ with $l(w)=n$. Assume first that $w = \cV_\alpha^{\beta\alpha} y = uv$ for $u,v,y \in \cS_\mathrm{adm}$ and $\theta(u) = \theta(v)$, $\theta(y) = \alpha$. Observe that $l(u) < l(w)$, as $v \in \cS_\mathrm{adm}$ is non-empty. Then $u = \cV_\alpha^{\beta\alpha} u^\prime$ for some $u^\prime \in \cS$ and we may apply $\mathrm{A}(n-1)$ to obtain $u = \cV_\alpha^{\beta\alpha} u^\dprime u^\tprime$ with $u^\dprime, u^\tprime \in \cS_\mathrm{adm}$, $\theta(u^\dprime) = \alpha$, $\theta(u^\tprime) = \beta\alpha$ (or $u^\tprime$ is empty), thus proving $\theta(u) = \beta\alpha$. Note that we also have $y = u^\dprime u^\tprime v \in \cS_\mathrm{adm}$, and by $\mathrm{B}(n-1)$ (and well-definedness of $\theta$) we may conclude that $\alpha = \theta(y) = \theta(u^\dprime) = \beta \alpha$. Hence this ambiguity may only arise in the case of using a letter of the form $\cV_\alpha^\alpha$, which does not lead to ambiguity with respect to $\theta$.\\
Assume finally that $w = uv = xy$ for $u,v,x,y \in \cS_\mathrm{adm}$ and $\theta(u) = \theta(v)$, $\theta(x) = \theta(y)$. We intend to prove that $\theta(u) = \theta(x)$. Again, we have two possibilities: Either $l(u) \leq l(x)$, or $l(x) < l(u)$. In the first case, according to $\mathrm{B}(n-1)$ we may conclude that $\theta(x) = \theta(u)$. Similarly, the second case implies $\theta(u) = \theta(x)$.
\end{proof}
\end{lem}
%
%
\begin{defn}
Now, for each $\alpha \in \cM_n$, we consider the submonoid $\cS_\alpha \defas \theta^{-1}(\alpha) \cup \{\varnothing\} \subseteq \cS_{\mathrm{adm}}$. Note that it is a graded submonoid, where a word $w \in \cS$ is graded using the grading of $\Omega^*_{\Cdot}$, i.e. $\abs{w} = \sum_{x_{\Cdot} \in w} \abs{x_{\Cdot}}$. We take the free abelian group with basis given by this submonoid, denoted
\begin{equation*}
  \hat\Omega^*_\alpha = \bigoplus\nolimits_{\cS_\alpha} \bZ.
\end{equation*}
and give it the structure of a graded ring, using concatenation of words $\cS_\alpha \times \cS_\alpha \to \cS_\alpha$ and extending bilinearly. This is also known as the (graded) monoid ring of $\cS_\alpha$ over $\bZ$, denoted as $\hat \Omega^*_\alpha = \bZ[\cS_\alpha]$.
\end{defn}
\begin{proof}[Proof of Theorem \ref{thm_existence_initial_object}]
Let $E^*_{\Cdot}$ be a Burnside-Witt complex over $A$, and let $\phi_{\Cdot}: W_\Cdot A \to E^0_{\Cdot}$ be the ring morphism from the Burnside-Witt vectors over $A$ to the degree $0$ part of the complex $E$. Recall that we are trying to find a morphism into every such $E$, out of a fixed object. From Prop.~\ref{prop_higher_de_rahm_complex} we know that we may extend $\phi_\Cdot$ to a morphism
\begin{equation*}
	\phi_\Cdot^*: \Omega^*_{\Cdot} = \Omega^*_{W_{\Cdot} A,n} \to E^*_{\Cdot}
\end{equation*}
of multidifferential algebras. We proceed to extend this to a map
\begin{equation*}
	\hat\phi_\Cdot^*: \hat\Omega^*_{\Cdot} \to E^*_{\Cdot}
\end{equation*}
and show that the collection of images of $\hat\phi_\Cdot^*$ for all $\Cdot \in \cM_n$ is a sub Burnside-Witt complex of $E$. We begin by defining the map on the monoid $\cS_\alpha$ (simultaneously for all $\alpha \in \cM_n$) by setting
\begin{itemize}
\item[] $x \in \Omega^*_{\alpha},\;\; \hat\phi_\alpha^*(x) \coloneqq \phi_\alpha^*(x)$,%
\item[] $w,w^\prime \in \cS_\alpha,\;\; \hat\phi_\alpha^*(ww^\prime) \coloneqq %
		\hat\phi_\alpha^*(w) \hat\phi_\alpha^*(w^\prime)$,%
\item[] $w \in \cS_\gamma, \beta \in \cM_n: \beta\gamma = \alpha,\;\;%
		\hat\phi_\alpha^*(\cV_\gamma^{\beta\gamma}w) \defas V_\gamma^{\beta\gamma} \hat\phi_\alpha^*(w),$
\end{itemize}
and sending the empty word to zero. We have to make sure that this is well-defined as a map of sets - by the second (and last) point, it is by definition a map of monoids. This may now be proven rather easily, using the statements and techniques of Lemma \ref{lem_theta_well_defined}: We proceed by induction over the length of a word $w \in \cS_\alpha$. For words of lenth $0$ and $1$, this follows immediately from the definition. Let $w \in \cS_\alpha$ with $l(w) = n \geq 2$. If $w = uv =xy$ for $u,v,x,y \in \cS_\mathrm{adm}$ and $\theta(u) = \theta(v)$, $\theta(x) = \theta(y)$, then $\theta(u) = \theta(x)$ (as we saw in the Lemma cited above) and $\hat\phi$ is well-defined on $w$, as it is well-defined on $u,v,x,$ and $y$ by induction. If $w = \cV_\alpha^{\beta\alpha} y$ for some non-empty $y \in \cS_\alpha$ and $\beta \neq \id$, no ambiguity is possible (as seen in the last part of the proof of the Lemma) and we have well-definedness by induction. If $\beta = \id$, then $\hat\phi_\alpha(\cV^\alpha_\alpha) = V^\alpha_\alpha \hat\phi_\alpha(y) = \hat\phi_\alpha(y)$ is again well-defined by induction.

We extend this map linearly to obtain a family of ring morphisms $\hat\phi_\alpha: \hat \Omega_\alpha \to E^*_\alpha$, ranging over $\alpha \in \cM_n$. We must prove that the sum of the images of this collection is a sub Burnside-Witt complex. We have to check that it has all the necessary structure: It is a subring, invariant under differentials and Verschiebung by construction. Note that it is also invariant under restriction operators, as they commute with all other operators. Again by construction it receives a map from the Burnside-Witt vectors, namely $\phi$. All that we must show is that it is invariant under Frobenius operators $F^\gamma=F_{\gamma\delta}^{\delta}$ for all $\gamma,\delta \in \cM_n$.

Frobenius are ring morphisms, hence it suffices to check words of the form $\cV^{\beta\alpha}_\alpha x_\alpha$ for some $\alpha,\beta \in \cM_n$ and $x\in \Omega^*_\alpha$, i.e. to show that $F^\gamma V_\beta x \in \im \hat \phi$, where $V_\beta = V_\alpha^{\beta\alpha}$. In the following arguments, a lot of indices will come up, and change. As the bookkeeping is rather tedious and completely pointless to this proof, we omit it and abuse notation (heavily) to keep the indices simple. We may use Frobenius reciprocity to obtain $F^\gamma V_\beta x = V_\beta F^\gamma x$ (with indices secretely changed) and proceed to analyze $F x$, leaving out the Verschiebung, as it suffices to show that $Fx$ is in the image. As $F$ is multiplicative, we may assume $x$, which is the image of an element in the multi-differential de~Rham complex, to consist of a single factor, i.e. $x = d_I (x^\prime)$ for some $x^\prime \in W_\Cdot A$ and $I \subset \ind{n} = \{1,\ldots,n\}$. Any element in the Burnside-Witt ring may be written as the sum of appropriate Verschiebung and Teichm\"uller morphism applied to its coordinates (cf. Rem. \ref{rem_teichmueller_sum}), namely
\begin{equation*}
	x^\prime = \sum_\alpha V_\alpha \Delta_\alpha (x^\prime_\alpha)
\end{equation*}
for appropriately chosen $\alpha \in \cM_n$ (again, what these exactly are matters not to this proof), $x^\prime_\alpha \in A$. Both the differential and Frobenius are additive, hence we may reduce to considering
\begin{equation*}
F^\gamma d_I V_\alpha \Delta_\alpha (x)
\end{equation*}
for $x \in A$.

For the next reduction, we must analyze terms of the form $F^\alpha d_I V_\beta$ for $\alpha,\beta \in \cM_n$ and $I \subset \ind{n}$. The appropriate relation for this situation is terribly involved to spell out (cf. Lem. \ref{lem_rel_FdV_higher_differentials}), but ignoring indices, it becomes rather pleasant:
\begin{equation*}
F d_I V = \sum_{A \subset I} d_A VF d_B
\end{equation*}
where $B \coloneqq I \setminus A$. Again we may ignore the outer differential and Verschiebung and finally arrive at $F d_I \Delta (a)$ for some $a \in A$. But, according to Cor. \ref{cor_fdw_relation_arbitrary_dimensions}, we may rewrite this in a form where no Frobenius operator is present, which proves that the image of $\hat\phi$ is closed under Frobenius operators, and hence concludes the proof of the theorem.
\end{proof}
%
%
\begin{lem}
The map
\begin{equation*}
	\hat \phi_\Cdot: \hat \Omega^*_\Cdot \to \cW_\Cdot \Omega^*_{A,n}
\end{equation*}
is surjective.
\begin{proof}
The argument is formal and standard category theory: As the image of the above map is a Burnside-Witt complex, it receives a map from the initial object. The composition of this map with the inclusion is a self-map of the initial object, so it must be the identity, hence the inclusion is surjective.
\end{proof}
\end{lem}
\comm{Morten, you may stop reading here, if you wish: what follows are mere notes.}\\
\comm{[put the rest in different statement! relations that hold in initial object]}
For each $\alpha,\beta \in \cM_n$ we define a morphism \comm{[necessary?]} of graded abelian groups
\begin{equation*}
	V_\alpha^{\beta\alpha}: \hat \Omega_\alpha^* \to \hat \Omega_{\beta\alpha}^*
\end{equation*}
by sending a word
$w \in \cS_\alpha$ to $V_\alpha^{\beta\alpha}(w) \defas \cV_\alpha^{\beta\alpha}w \in \cS_{\beta\alpha}$ and extending this linearly. Finally, \\
We now have a formal ring structure, Verschiebungs operators and $\Omega^*_\alpha$. We should identify the formal ring structure with the ring structure already present on $\Omega^*_{\alpha}$. To this end we take the graded ideal $\cI_\alpha^* \subseteq \hat \Omega_\alpha^*$ generated by the following elements:\\
\comm{[divide into what relations are needed for proof of theorem, and rest]}\\
\comm{[rest being which other relations we can divide out]}
\begin{itemize}
%\item Given $w=x, w^\prime = x^\prime \in \cS_\alpha$ for $x, x^\prime \in \Omega^*_{W_\alpha A}$ we take $w + w^\prime - v$, where $w \defas y \in \cS_\alpha$ with $y \defas x + x^\prime \in \Omega^*_{W_\alpha A}$;
\item $(w + w^\prime - v) \in \hat\Omega_\alpha^*$ for all $w = x_\alpha$, $w^\prime =%
  x^\prime_\alpha$, $v = (x+x^\prime)_\alpha \in \cS_\alpha$ with $x, \; x^\prime \in%
  \Omega^*_{\alpha},$
\item $(ww^\prime - v) \in \hat\Omega_\alpha^{k+l}$ for all $w = x_\alpha$, $w^\prime =%
  x^\prime_\alpha$, $v = (x \cdot x^\prime)_\alpha \in \cS_\alpha$, with $x \in %
  \Omega^k_{\alpha}$, $x^\prime \in \Omega^l_{\alpha},$
\end{itemize}
and consider the quotient $\tilde \Omega^*_{\alpha} \defas (\hat \Omega_\alpha / \cI) ^*$. This quotient admits a map
\begin{equation}
  \Omega^*_{\Cdot}
\end{equation}
For (extended) functoriality of the Verschiebung operators, we include %
\begin{itemize}
\item $(\cV_{\gamma\beta}^{\delta\gamma\beta} \cV_{\beta}^{\gamma\beta} w - \cV_{\beta}^{\delta\gamma\beta} w ) \in \hat \Omega^*_\alpha$ for all
$w \in S_\beta, \beta,\gamma, \delta \in \cM_n, \delta\gamma\beta\ = \alpha$
\end{itemize}
on the one hand, while taking care of $V_\beta^{\gamma\beta} = \id$ for invertible $\gamma \in \cM_n$ on the other hand is a bit more involved:
Let $\beta, \gamma \in \cM_n$ with $\gamma\beta = \alpha$ and $\gamma$ invertible. We introduce an equivalence relation on $\cS_{\alpha}$ by defining $\hat w \in \cS_{\alpha}$ for each $w \in \cS_\beta$ and setting $\cV_\beta^{\gamma\beta} w \sim \hat w$, using induction on the length $l(w) \geq 1$ of $w$:
Let $w = x_\beta$ for some $x \in \Omega^*_{W_\beta A}$, then $\hat w \defas x_{\gamma\beta} = x_\alpha \in \cS_\alpha$. Note that since $\gamma$ is invertible, we have $L_\beta = L_{\gamma\beta}$, $W_\beta A = W_{L_\beta} A = W_{L_{\gamma\beta}} A  = W_{\gamma\beta} A$ and finally $\Omega^*_{W_\beta A} = \Omega^*_{W_{\gamma\beta} A}$, making this well-defined.\\
Now let $w \in \cS_\beta$ be of length at least two. We differentiate two cases: Let %
$w = \cV_\delta^{\epsilon\delta} v$ for $v \in \cS_\delta$, $\delta, \epsilon \in \cM_n$ with $\epsilon\delta = \beta$. Then we set $ \cV_\beta^{\gamma\beta} w = %
  \cV_\beta^{\gamma\beta} \cV_\delta^{\epsilon\delta} v \sim %
  \cV_\delta^{\gamma\epsilon\delta} v$. %
If $\epsilon$ and hence $\gamma\epsilon$ is not invertible, we set $\hat w \defas \cV_\delta^{\gamma\epsilon\delta} v \in \cS_{\alpha}$. If $\epsilon$ is invertible, then so is $\gamma\epsilon$, and as $v$ is shorter than $w$, by induction there is $\hat v \in \cS_{\gamma\epsilon\delta} = \cS_{\alpha}$ with $\cV_\delta^{\gamma\epsilon\delta} v \sim \hat v$, and we set $\hat w \defas \hat v$.\\
For the other case, assume that $w = uv$ for some $u,v \in \cS_\beta$. As $l(u) < l(w)$ and $l(v) < l(w)$, by induction there are $\hat u, \hat v \in \cS_{\gamma\beta} = \cS_\alpha$ as above, and we set $\hat w \defas \hat u \hat v$. Thus we include in the ideal the elements
\begin{itemize}
\item $(\cV_\beta^{\gamma\beta} w - \hat w ) \in \hat \Omega^*_{\alpha}$ for all %
  $\beta, \gamma \in \cM_n$ with $\gamma\beta = \alpha$ and $\gamma$ invertible, $w \in \cS_\beta$, $\hat w \in \cS_{\gamma\beta} = \cS_\alpha$ as defined above.
\end{itemize}
We go further and interpret the symbols $\cV$ in degree $0$, adding
\begin{itemize}
\item $(\cV_\beta^{\gamma\beta} x - y) \in \hat \Omega^0_{\alpha}$ for all %
  $\beta, \gamma \in \cM_n$ with $\gamma\beta= \alpha$, $x \in \Omega^0_{W_\beta A} = W_\beta A$, %
  where $y = V_\beta^{\gamma\beta} (x) \in W_{\alpha} A$.
  %BAZINGA interpret in higher degrees? use relation Vd = dV?
\end{itemize}
Finally, we make the multiplication graded commutative:
\begin{itemize}
\item $(w w^\prime - (-1)^{kl} w^\prime w) \in \hat\Omega^{k+l}_\alpha$ for all $w \in \hat\Omega^k_\alpha, w^\prime \in \tilde\Omega^l_\alpha$
\end{itemize}
We let all these elements generate the graded ideal $\cI_\alpha^*$. We want the relations to be closed under concatenation as well as under applying the Verschiebung operators. To this end, we need to iterate concatenation and Verschiebung as follows: Define an ascending sequence of graded ideals $\hat\cI_\alpha^{*\,(n)} \subseteq \hat\cI_\alpha^{*\,(n+1)}$ for all $n \geq 0$ by setting $\hat\cI_\alpha^{*\,(0)} \defas \cI_\alpha^*$ and letting $\hat\cI_\alpha^{*\,(n+1)}$ be the graded ideal generated by%
    \[\bigcup_{\beta,\gamma} V_\beta^{\gamma\beta}(\hat\cI_\beta^{*\,(n)}),\]%
where the union is taken over all $\beta,\gamma \in \cM_n$ with $\gamma\beta=\alpha$. We collect these into $\hat\cI_\alpha^{*} \defas \bigcup_{n \geq 0} \hat\cI_\alpha^{*\,(n)}$, to at last obtain, for each $\alpha \in \cM_n$. the graded commutative graded ring%
    \[\tilde\Omega_\alpha^* \defas \hat\Omega_\alpha^* / \hat\cI_\alpha^*.\]
%
%
\section{Calculations}
We proceed to record calculations on the de Rham-Burnside-Witt complex. We assume the ground ring to be $\bF_p$, the field with $p$ elements, where $p$ is at least an odd prime, possibly even greater or equal to 5. We will at first only consider the case $n=2$. Since we're ultimately interested in $p$-complete calculations of TC, we reduce ourselves to $p$-adic subgroups given by diagonalized matrices.\\
There is not a lot of hope of understanding the Burnside-Witt ring as a ring, even for the abelian groups $\bZ/p^n\bZ \times \bZ/p^m\bZ$ for $n,m \geq 2$, so we are going to treat these as underlying black boxes and try to use relations between the differentials and other structure morphism to gain an understanding of the dRBW-complex in positive degrees.\\
We are working our way up from the bottom, starting with $G=\{e\}$, the trivial group, corresponding to $\alpha = \id$, the identity matrix. Here we have $W_G A = A$. Note that for any commutative ring $R$ with $\bZ \to R$ surjective, the module of K\"ahler differentials is zero, as the differential is zero on constants in $R$, i.e. elements of the form $n \cdot 1$ for $n \in \bZ$. This also holds, by construction, for one-dimensional and thus for all differentials in the higher de Rham complex on $W_G A = A$, hence $\cW_{\id}\Omega^* \cong 0$ for $* \geq 1$\\
Let $\alpha = \diag(p^n, 1)$ or $\alpha = \diag(1,p^n)$ for some $n \geq 0$. Then $L_\alpha \cong \bZ/p^n\bZ$ and the Brunside-Witt vectors are isomorphic to the truncated $p$-typical Witt vectors, yielding $W_\alpha A \cong \bZ/p^{n+1}\bZ$ \comm{[add reference or make Lemma]}. But then $\bZ \to W_\alpha A$ is surjective, and as above we have $\cW_{\alpha}\Omega^* \cong 0$ for $* \geq 1$.\\
In the following discussion, we will readily jump between matrices $\alpha \in \cM_n$, their kernels $L_\alpha \subset \gT^n$ as maps of the torus, and the "standard" p-groups they are isomorphic to. The latter description will be used to determine the subgroup lattice, the former to apply relations and structure maps. Note that we will write column vectors as row vectors as to make the exposition more readable. Note also that we discuss relations on the generators $\omega_H (a)$ for $H \leq G$ and $a \in A$ (cf. Rem. \ref{rem_witt_ghost_generators_multiplication}).
The next case is $\alpha = \diag(p,p)$ with $L_\alpha = \langle (1/p,0), (0,1/p) \rangle \cong \bZ/p\bZ \times \bZ/p\bZ \asdef G$. The latter may be interpreted as $\bF_p^2$, the vector space of dimension 2 over $\bF_p$, and the subgroups are exactly given as subspaces, which are easily characterized as the two obvious ones, $0, G$, as well as the one-dimensional ones $H_k \defas \langle (k,1) \rangle \subset \bZ/p\bZ \times \bZ/p\bZ$ for $k \in \bF_p$ and $H_\infty \defas \langle (1,0) \rangle$. We have $H_k \cong \langle (k/p,1/p) \rangle = L_{\beta_k}$ with %
$\beta_k = \left( \begin{smallmatrix} 1 & -k \\ 0 & p \end{smallmatrix} \right)$ and $\H_\infty \cong \langle (1/p,0) \rangle = L_{\beta_\infty}$ with $\beta_\infty = \diag(p,1)$.\\
Our first strategy is to obtain information by pulling elements up from lower groups, which can be done with the Verschiebung operators $V_\gamma = V_{\beta}^{\gamma\beta}: W_\beta A \to W_{\gamma\beta} A$ (multiplying matrices potentially increases kernels!), using the relation%
\[d_{\gamma v} V_\gamma = V_\gamma d_v\]%
as well as the formula (cf. Def. \ref{def_witt_vers})
\[ V_\gamma: W_H A \to W_G A, \; \omega_K (a) \mapsto \omega_K (a). \]
We utilize that for any cyclic subgroup $H \leq G$, the differentials disappear on $W_H A$ (which itself is cyclic), hence using the above relation we can deduce that they disappear for any element pushed up by a Verschiebung $V_\gamma$ from such a $W_H A$, at least for those differentials that are indexed by / corespond to vectors in the image of $\gamma$. Indeed, for $x \in W_H A$ for $H$ cyclic we have
\begin{equation*}
	d_{\gamma v} V_\gamma (x) = V_\gamma d_v (x) = 0,
\end{equation*}
where it suffices to consider $v \in \{e_1,e_2\}$. Hence we just need to determine $\gamma_H$ for every cyclic subgroup $H$ to obtain the appropriate relations.\\
Consider $H_\infty \cong L_{\beta_\infty}$. We are looking for $\gamma_\infty$ with $\alpha = \gamma_\infty\beta_\infty$, for then we may use
\begin{equation*}
	V_{\gamma_\infty} = V_{\beta_\infty}^{\gamma_\infty\beta_\infty} = %
	V_{\beta_\infty}^{\alpha}: W_{H_\infty} A \to W_G A.
\end{equation*}
This is given by $\gamma_\infty = \diag(1,p)$, hence we obtain the relations
\begin{equation}\label{eq_group_diag(p,p)_subgroup_diag(1,p)}
	0 = d_1(\omega_{H_\infty}(a)) = p d_2 (\omega_{H_\infty}(a))
\end{equation}
for all $a \in A$. where we used linearity of a differential in its index.\\
Similarly, we have $\gamma_k \defas \inmatrixtwo{p}{k}{0}{1}$ with $\alpha = \gamma_k \beta_k$, and hence
\begin{equation}\label{eq_group_diag(p,p)_subgroup_(p,k_0,1)}
	0 = p d_1  \omega_{H_k}(a) = (k d_1 + d_2) \omega_{H_k}(a).
\end{equation}
Denoting the trivial subgroup by abuse of notation as $e \defas \{e\} \leq G$, we observe that $\omega_e(a)$ is in the image of both $V_{\gamma_\infty}$ and $V_{H_0}$, hence we also obtain
\begin{equation*}
	0 = d_1(\omega_e(a)) = d_2 (\omega_e(a)).
\end{equation*}
We may deduce another relation, using the following: Note that the multiplication of elements of the form $\omega_G(a)$ is quite simply given by $\omega_G (a) \omega_G (b) = \omega_G (ab)$, cf. Remark \ref{rem_witt_ghost_generators_multiplication}, and that $\omega_G(1)$ is the unit of the multiplication in $W_G A$. Taking an $a \in A = \bF_p$, we have the identity $a^{p-1} = 1$ (and hence $a^p=a$), and using that $d_i$ is a derivation for $i \in \{1,2\}$, we get
\begin{gather*}
	d_i(\omega_G(a)) = d_i(\omega_G(a^p)) = d_i(\omega_G(a)^p) = p \omega_G(a)^{p-1} d_i(\omega_G(a)) = \\ %
	p \omega_G(a^{p-1}) d_i(\omega_G(a)) = p \omega_G(1) d_i(\omega_G(a)) = p d_i(\omega_G(a)). %
\end{gather*}
\comm{[whatever that means!?]} In the not $p$-completed setting, over the usual torus, everything is just abelian groups, and the differentials are (a priori) free abelian groups, hence this literally just introduces the relation $(p-1)d_i (\omega_G(a)) = 0$. In the $p$-completed setting, everything is a module over the $p$-adic integers. They are a PID. But: modules can have torsion, even over PID's (duh). So still nothing more to say!? Not quite: have $p d_i (\omega_G(a)) = d_i (\omega_G(a))$, $\bZ_p$ local ring, Nakayama's Lemma implies that the finitely generated $\bZ_p$ module generated by $d_i (\omega_G(a))$ is zero, hence $d_i (\omega_G(a)) = 0$. ha! find reference for Nakayama's Lemma (lang?). Note that the above calculation does not depend on $G$, hence for any $G = L_\alpha$ we have $d_i(\omega_G(a)) = 0$ for all $i\in \ind{n},\, a \in A$, at least over $\bZ_p$.\\
Let's move on to the next group.
%%%%%%%%%%%%%%%%% bibliography %%%%%%%%%%%%%%%%%%%%
\bibliographystyle{alpha}
\bibliography{biblio}
%%%%%%%%%%%%%%%%%%% the end %%%%%%%%%%%%%%%%%%%%%
\end{document}
